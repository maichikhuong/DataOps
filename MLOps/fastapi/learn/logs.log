2025-06-26 23:21:57,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-26 23:21:57,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-26 23:21:57,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-26 23:21:57,638:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-26 23:22:21,435:INFO:PyCaret RegressionExperiment
2025-06-26 23:22:21,435:INFO:Logging name: reg-default-name
2025-06-26 23:22:21,435:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-26 23:22:21,437:INFO:version 3.3.2
2025-06-26 23:22:21,437:INFO:Initializing setup()
2025-06-26 23:22:21,437:INFO:self.USI: aea4
2025-06-26 23:22:21,437:INFO:self._variable_keys: {'fold_generator', 'y', 'fold_groups_param', 'log_plots_param', 'seed', '_available_plots', 'fold_shuffle_param', 'idx', 'memory', 'logging_param', 'y_train', 'y_test', 'X', 'exp_name_log', 'gpu_param', 'html_param', 'USI', '_ml_usecase', 'data', 'target_param', 'X_test', 'transform_target_param', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train'}
2025-06-26 23:22:21,437:INFO:Checking environment
2025-06-26 23:22:21,437:INFO:python_version: 3.11.9
2025-06-26 23:22:21,437:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-26 23:22:21,437:INFO:machine: AMD64
2025-06-26 23:22:21,437:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-26 23:22:21,443:INFO:Memory: svmem(total=66342375424, available=42345308160, percent=36.2, used=23997067264, free=42345308160)
2025-06-26 23:22:21,443:INFO:Physical Core: 8
2025-06-26 23:22:21,443:INFO:Logical Core: 16
2025-06-26 23:22:21,443:INFO:Checking libraries
2025-06-26 23:22:21,443:INFO:System:
2025-06-26 23:22:21,443:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-26 23:22:21,443:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-26 23:22:21,443:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-26 23:22:21,443:INFO:PyCaret required dependencies:
2025-06-26 23:22:21,496:INFO:                 pip: 25.1.1
2025-06-26 23:22:21,496:INFO:          setuptools: 65.5.0
2025-06-26 23:22:21,496:INFO:             pycaret: 3.3.2
2025-06-26 23:22:21,496:INFO:             IPython: 9.3.0
2025-06-26 23:22:21,497:INFO:          ipywidgets: 8.1.7
2025-06-26 23:22:21,497:INFO:                tqdm: 4.67.1
2025-06-26 23:22:21,497:INFO:               numpy: 1.26.4
2025-06-26 23:22:21,497:INFO:              pandas: 2.1.4
2025-06-26 23:22:21,497:INFO:              jinja2: 3.1.6
2025-06-26 23:22:21,497:INFO:               scipy: 1.11.4
2025-06-26 23:22:21,497:INFO:              joblib: 1.3.2
2025-06-26 23:22:21,497:INFO:             sklearn: 1.4.2
2025-06-26 23:22:21,497:INFO:                pyod: 2.0.5
2025-06-26 23:22:21,497:INFO:            imblearn: 0.13.0
2025-06-26 23:22:21,497:INFO:   category_encoders: 2.7.0
2025-06-26 23:22:21,497:INFO:            lightgbm: 4.6.0
2025-06-26 23:22:21,497:INFO:               numba: 0.61.2
2025-06-26 23:22:21,497:INFO:            requests: 2.32.4
2025-06-26 23:22:21,497:INFO:          matplotlib: 3.7.5
2025-06-26 23:22:21,497:INFO:          scikitplot: 0.3.7
2025-06-26 23:22:21,497:INFO:         yellowbrick: 1.5
2025-06-26 23:22:21,497:INFO:              plotly: 5.24.1
2025-06-26 23:22:21,497:INFO:    plotly-resampler: Not installed
2025-06-26 23:22:21,497:INFO:             kaleido: 1.0.0
2025-06-26 23:22:21,497:INFO:           schemdraw: 0.15
2025-06-26 23:22:21,497:INFO:         statsmodels: 0.14.4
2025-06-26 23:22:21,497:INFO:              sktime: 0.26.0
2025-06-26 23:22:21,497:INFO:               tbats: 1.1.3
2025-06-26 23:22:21,497:INFO:            pmdarima: 2.0.4
2025-06-26 23:22:21,497:INFO:              psutil: 7.0.0
2025-06-26 23:22:21,497:INFO:          markupsafe: 3.0.2
2025-06-26 23:22:21,497:INFO:             pickle5: Not installed
2025-06-26 23:22:21,497:INFO:         cloudpickle: 3.1.1
2025-06-26 23:22:21,497:INFO:         deprecation: 2.1.0
2025-06-26 23:22:21,497:INFO:              xxhash: 3.5.0
2025-06-26 23:22:21,497:INFO:           wurlitzer: Not installed
2025-06-26 23:22:21,497:INFO:PyCaret optional dependencies:
2025-06-26 23:22:21,502:INFO:                shap: Not installed
2025-06-26 23:22:21,502:INFO:           interpret: Not installed
2025-06-26 23:22:21,502:INFO:                umap: Not installed
2025-06-26 23:22:21,502:INFO:     ydata_profiling: Not installed
2025-06-26 23:22:21,502:INFO:  explainerdashboard: Not installed
2025-06-26 23:22:21,502:INFO:             autoviz: Not installed
2025-06-26 23:22:21,502:INFO:           fairlearn: Not installed
2025-06-26 23:22:21,502:INFO:          deepchecks: Not installed
2025-06-26 23:22:21,502:INFO:             xgboost: Not installed
2025-06-26 23:22:21,502:INFO:            catboost: Not installed
2025-06-26 23:22:21,502:INFO:              kmodes: Not installed
2025-06-26 23:22:21,502:INFO:             mlxtend: Not installed
2025-06-26 23:22:21,502:INFO:       statsforecast: Not installed
2025-06-26 23:22:21,502:INFO:        tune_sklearn: Not installed
2025-06-26 23:22:21,502:INFO:                 ray: Not installed
2025-06-26 23:22:21,502:INFO:            hyperopt: Not installed
2025-06-26 23:22:21,502:INFO:              optuna: Not installed
2025-06-26 23:22:21,502:INFO:               skopt: Not installed
2025-06-26 23:22:21,502:INFO:              mlflow: Not installed
2025-06-26 23:22:21,502:INFO:              gradio: Not installed
2025-06-26 23:22:21,502:INFO:             fastapi: Not installed
2025-06-26 23:22:21,502:INFO:             uvicorn: Not installed
2025-06-26 23:22:21,502:INFO:              m2cgen: Not installed
2025-06-26 23:22:21,502:INFO:           evidently: Not installed
2025-06-26 23:22:21,502:INFO:               fugue: Not installed
2025-06-26 23:22:21,502:INFO:           streamlit: Not installed
2025-06-26 23:22:21,502:INFO:             prophet: Not installed
2025-06-26 23:22:21,502:INFO:None
2025-06-26 23:22:21,502:INFO:Set up data.
2025-06-26 23:22:48,841:INFO:PyCaret RegressionExperiment
2025-06-26 23:22:48,841:INFO:Logging name: reg-default-name
2025-06-26 23:22:48,841:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-26 23:22:48,841:INFO:version 3.3.2
2025-06-26 23:22:48,841:INFO:Initializing setup()
2025-06-26 23:22:48,841:INFO:self.USI: 16f6
2025-06-26 23:22:48,841:INFO:self._variable_keys: {'fold_generator', 'y', 'fold_groups_param', 'log_plots_param', 'seed', '_available_plots', 'fold_shuffle_param', 'idx', 'memory', 'logging_param', 'y_train', 'y_test', 'X', 'exp_name_log', 'gpu_param', 'html_param', 'USI', '_ml_usecase', 'data', 'target_param', 'X_test', 'transform_target_param', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train'}
2025-06-26 23:22:48,841:INFO:Checking environment
2025-06-26 23:22:48,841:INFO:python_version: 3.11.9
2025-06-26 23:22:48,841:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-26 23:22:48,841:INFO:machine: AMD64
2025-06-26 23:22:48,841:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-26 23:22:48,847:INFO:Memory: svmem(total=66342375424, available=41894559744, percent=36.9, used=24447815680, free=41894559744)
2025-06-26 23:22:48,847:INFO:Physical Core: 8
2025-06-26 23:22:48,847:INFO:Logical Core: 16
2025-06-26 23:22:48,847:INFO:Checking libraries
2025-06-26 23:22:48,847:INFO:System:
2025-06-26 23:22:48,847:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-26 23:22:48,847:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-26 23:22:48,847:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-26 23:22:48,847:INFO:PyCaret required dependencies:
2025-06-26 23:22:48,847:INFO:                 pip: 25.1.1
2025-06-26 23:22:48,847:INFO:          setuptools: 65.5.0
2025-06-26 23:22:48,847:INFO:             pycaret: 3.3.2
2025-06-26 23:22:48,847:INFO:             IPython: 9.3.0
2025-06-26 23:22:48,847:INFO:          ipywidgets: 8.1.7
2025-06-26 23:22:48,847:INFO:                tqdm: 4.67.1
2025-06-26 23:22:48,847:INFO:               numpy: 1.26.4
2025-06-26 23:22:48,847:INFO:              pandas: 2.1.4
2025-06-26 23:22:48,847:INFO:              jinja2: 3.1.6
2025-06-26 23:22:48,847:INFO:               scipy: 1.11.4
2025-06-26 23:22:48,847:INFO:              joblib: 1.3.2
2025-06-26 23:22:48,847:INFO:             sklearn: 1.4.2
2025-06-26 23:22:48,847:INFO:                pyod: 2.0.5
2025-06-26 23:22:48,847:INFO:            imblearn: 0.13.0
2025-06-26 23:22:48,847:INFO:   category_encoders: 2.7.0
2025-06-26 23:22:48,847:INFO:            lightgbm: 4.6.0
2025-06-26 23:22:48,847:INFO:               numba: 0.61.2
2025-06-26 23:22:48,847:INFO:            requests: 2.32.4
2025-06-26 23:22:48,847:INFO:          matplotlib: 3.7.5
2025-06-26 23:22:48,847:INFO:          scikitplot: 0.3.7
2025-06-26 23:22:48,847:INFO:         yellowbrick: 1.5
2025-06-26 23:22:48,847:INFO:              plotly: 5.24.1
2025-06-26 23:22:48,847:INFO:    plotly-resampler: Not installed
2025-06-26 23:22:48,847:INFO:             kaleido: 1.0.0
2025-06-26 23:22:48,847:INFO:           schemdraw: 0.15
2025-06-26 23:22:48,847:INFO:         statsmodels: 0.14.4
2025-06-26 23:22:48,847:INFO:              sktime: 0.26.0
2025-06-26 23:22:48,847:INFO:               tbats: 1.1.3
2025-06-26 23:22:48,847:INFO:            pmdarima: 2.0.4
2025-06-26 23:22:48,847:INFO:              psutil: 7.0.0
2025-06-26 23:22:48,847:INFO:          markupsafe: 3.0.2
2025-06-26 23:22:48,847:INFO:             pickle5: Not installed
2025-06-26 23:22:48,847:INFO:         cloudpickle: 3.1.1
2025-06-26 23:22:48,847:INFO:         deprecation: 2.1.0
2025-06-26 23:22:48,847:INFO:              xxhash: 3.5.0
2025-06-26 23:22:48,847:INFO:           wurlitzer: Not installed
2025-06-26 23:22:48,847:INFO:PyCaret optional dependencies:
2025-06-26 23:22:48,847:INFO:                shap: Not installed
2025-06-26 23:22:48,847:INFO:           interpret: Not installed
2025-06-26 23:22:48,847:INFO:                umap: Not installed
2025-06-26 23:22:48,847:INFO:     ydata_profiling: Not installed
2025-06-26 23:22:48,847:INFO:  explainerdashboard: Not installed
2025-06-26 23:22:48,847:INFO:             autoviz: Not installed
2025-06-26 23:22:48,847:INFO:           fairlearn: Not installed
2025-06-26 23:22:48,847:INFO:          deepchecks: Not installed
2025-06-26 23:22:48,847:INFO:             xgboost: Not installed
2025-06-26 23:22:48,847:INFO:            catboost: Not installed
2025-06-26 23:22:48,847:INFO:              kmodes: Not installed
2025-06-26 23:22:48,847:INFO:             mlxtend: Not installed
2025-06-26 23:22:48,847:INFO:       statsforecast: Not installed
2025-06-26 23:22:48,847:INFO:        tune_sklearn: Not installed
2025-06-26 23:22:48,847:INFO:                 ray: Not installed
2025-06-26 23:22:48,847:INFO:            hyperopt: Not installed
2025-06-26 23:22:48,847:INFO:              optuna: Not installed
2025-06-26 23:22:48,847:INFO:               skopt: Not installed
2025-06-26 23:22:48,847:INFO:              mlflow: Not installed
2025-06-26 23:22:48,847:INFO:              gradio: Not installed
2025-06-26 23:22:48,847:INFO:             fastapi: Not installed
2025-06-26 23:22:48,847:INFO:             uvicorn: Not installed
2025-06-26 23:22:48,847:INFO:              m2cgen: Not installed
2025-06-26 23:22:48,847:INFO:           evidently: Not installed
2025-06-26 23:22:48,847:INFO:               fugue: Not installed
2025-06-26 23:22:48,847:INFO:           streamlit: Not installed
2025-06-26 23:22:48,847:INFO:             prophet: Not installed
2025-06-26 23:22:48,847:INFO:None
2025-06-26 23:22:48,847:INFO:Set up data.
2025-06-26 23:22:53,350:INFO:PyCaret RegressionExperiment
2025-06-26 23:22:53,350:INFO:Logging name: reg-default-name
2025-06-26 23:22:53,350:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-26 23:22:53,350:INFO:version 3.3.2
2025-06-26 23:22:53,350:INFO:Initializing setup()
2025-06-26 23:22:53,350:INFO:self.USI: 1b47
2025-06-26 23:22:53,350:INFO:self._variable_keys: {'fold_generator', 'y', 'fold_groups_param', 'log_plots_param', 'seed', '_available_plots', 'fold_shuffle_param', 'idx', 'memory', 'logging_param', 'y_train', 'y_test', 'X', 'exp_name_log', 'gpu_param', 'html_param', 'USI', '_ml_usecase', 'data', 'target_param', 'X_test', 'transform_target_param', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train'}
2025-06-26 23:22:53,350:INFO:Checking environment
2025-06-26 23:22:53,350:INFO:python_version: 3.11.9
2025-06-26 23:22:53,350:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-26 23:22:53,350:INFO:machine: AMD64
2025-06-26 23:22:53,350:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-26 23:22:53,357:INFO:Memory: svmem(total=66342375424, available=41073975296, percent=38.1, used=25268400128, free=41073975296)
2025-06-26 23:22:53,357:INFO:Physical Core: 8
2025-06-26 23:22:53,357:INFO:Logical Core: 16
2025-06-26 23:22:53,357:INFO:Checking libraries
2025-06-26 23:22:53,357:INFO:System:
2025-06-26 23:22:53,357:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-26 23:22:53,357:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-26 23:22:53,357:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-26 23:22:53,357:INFO:PyCaret required dependencies:
2025-06-26 23:22:53,357:INFO:                 pip: 25.1.1
2025-06-26 23:22:53,357:INFO:          setuptools: 65.5.0
2025-06-26 23:22:53,357:INFO:             pycaret: 3.3.2
2025-06-26 23:22:53,357:INFO:             IPython: 9.3.0
2025-06-26 23:22:53,357:INFO:          ipywidgets: 8.1.7
2025-06-26 23:22:53,357:INFO:                tqdm: 4.67.1
2025-06-26 23:22:53,357:INFO:               numpy: 1.26.4
2025-06-26 23:22:53,357:INFO:              pandas: 2.1.4
2025-06-26 23:22:53,357:INFO:              jinja2: 3.1.6
2025-06-26 23:22:53,357:INFO:               scipy: 1.11.4
2025-06-26 23:22:53,357:INFO:              joblib: 1.3.2
2025-06-26 23:22:53,357:INFO:             sklearn: 1.4.2
2025-06-26 23:22:53,357:INFO:                pyod: 2.0.5
2025-06-26 23:22:53,357:INFO:            imblearn: 0.13.0
2025-06-26 23:22:53,357:INFO:   category_encoders: 2.7.0
2025-06-26 23:22:53,357:INFO:            lightgbm: 4.6.0
2025-06-26 23:22:53,357:INFO:               numba: 0.61.2
2025-06-26 23:22:53,357:INFO:            requests: 2.32.4
2025-06-26 23:22:53,357:INFO:          matplotlib: 3.7.5
2025-06-26 23:22:53,357:INFO:          scikitplot: 0.3.7
2025-06-26 23:22:53,357:INFO:         yellowbrick: 1.5
2025-06-26 23:22:53,357:INFO:              plotly: 5.24.1
2025-06-26 23:22:53,357:INFO:    plotly-resampler: Not installed
2025-06-26 23:22:53,357:INFO:             kaleido: 1.0.0
2025-06-26 23:22:53,357:INFO:           schemdraw: 0.15
2025-06-26 23:22:53,357:INFO:         statsmodels: 0.14.4
2025-06-26 23:22:53,357:INFO:              sktime: 0.26.0
2025-06-26 23:22:53,357:INFO:               tbats: 1.1.3
2025-06-26 23:22:53,357:INFO:            pmdarima: 2.0.4
2025-06-26 23:22:53,357:INFO:              psutil: 7.0.0
2025-06-26 23:22:53,357:INFO:          markupsafe: 3.0.2
2025-06-26 23:22:53,357:INFO:             pickle5: Not installed
2025-06-26 23:22:53,357:INFO:         cloudpickle: 3.1.1
2025-06-26 23:22:53,357:INFO:         deprecation: 2.1.0
2025-06-26 23:22:53,357:INFO:              xxhash: 3.5.0
2025-06-26 23:22:53,358:INFO:           wurlitzer: Not installed
2025-06-26 23:22:53,358:INFO:PyCaret optional dependencies:
2025-06-26 23:22:53,358:INFO:                shap: Not installed
2025-06-26 23:22:53,358:INFO:           interpret: Not installed
2025-06-26 23:22:53,358:INFO:                umap: Not installed
2025-06-26 23:22:53,358:INFO:     ydata_profiling: Not installed
2025-06-26 23:22:53,358:INFO:  explainerdashboard: Not installed
2025-06-26 23:22:53,358:INFO:             autoviz: Not installed
2025-06-26 23:22:53,358:INFO:           fairlearn: Not installed
2025-06-26 23:22:53,358:INFO:          deepchecks: Not installed
2025-06-26 23:22:53,358:INFO:             xgboost: Not installed
2025-06-26 23:22:53,358:INFO:            catboost: Not installed
2025-06-26 23:22:53,358:INFO:              kmodes: Not installed
2025-06-26 23:22:53,358:INFO:             mlxtend: Not installed
2025-06-26 23:22:53,358:INFO:       statsforecast: Not installed
2025-06-26 23:22:53,358:INFO:        tune_sklearn: Not installed
2025-06-26 23:22:53,358:INFO:                 ray: Not installed
2025-06-26 23:22:53,358:INFO:            hyperopt: Not installed
2025-06-26 23:22:53,358:INFO:              optuna: Not installed
2025-06-26 23:22:53,358:INFO:               skopt: Not installed
2025-06-26 23:22:53,358:INFO:              mlflow: Not installed
2025-06-26 23:22:53,358:INFO:              gradio: Not installed
2025-06-26 23:22:53,358:INFO:             fastapi: Not installed
2025-06-26 23:22:53,358:INFO:             uvicorn: Not installed
2025-06-26 23:22:53,358:INFO:              m2cgen: Not installed
2025-06-26 23:22:53,358:INFO:           evidently: Not installed
2025-06-26 23:22:53,358:INFO:               fugue: Not installed
2025-06-26 23:22:53,358:INFO:           streamlit: Not installed
2025-06-26 23:22:53,358:INFO:             prophet: Not installed
2025-06-26 23:22:53,358:INFO:None
2025-06-26 23:22:53,358:INFO:Set up data.
2025-06-26 23:23:04,012:INFO:PyCaret RegressionExperiment
2025-06-26 23:23:04,012:INFO:Logging name: reg-default-name
2025-06-26 23:23:04,012:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-26 23:23:04,012:INFO:version 3.3.2
2025-06-26 23:23:04,012:INFO:Initializing setup()
2025-06-26 23:23:04,012:INFO:self.USI: 79e8
2025-06-26 23:23:04,012:INFO:self._variable_keys: {'fold_generator', 'y', 'fold_groups_param', 'log_plots_param', 'seed', '_available_plots', 'fold_shuffle_param', 'idx', 'memory', 'logging_param', 'y_train', 'y_test', 'X', 'exp_name_log', 'gpu_param', 'html_param', 'USI', '_ml_usecase', 'data', 'target_param', 'X_test', 'transform_target_param', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train'}
2025-06-26 23:23:04,012:INFO:Checking environment
2025-06-26 23:23:04,012:INFO:python_version: 3.11.9
2025-06-26 23:23:04,012:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-26 23:23:04,012:INFO:machine: AMD64
2025-06-26 23:23:04,012:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-26 23:23:04,016:INFO:Memory: svmem(total=66342375424, available=41077055488, percent=38.1, used=25265319936, free=41077055488)
2025-06-26 23:23:04,016:INFO:Physical Core: 8
2025-06-26 23:23:04,016:INFO:Logical Core: 16
2025-06-26 23:23:04,016:INFO:Checking libraries
2025-06-26 23:23:04,016:INFO:System:
2025-06-26 23:23:04,016:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-26 23:23:04,016:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-26 23:23:04,016:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-26 23:23:04,016:INFO:PyCaret required dependencies:
2025-06-26 23:23:04,016:INFO:                 pip: 25.1.1
2025-06-26 23:23:04,016:INFO:          setuptools: 65.5.0
2025-06-26 23:23:04,016:INFO:             pycaret: 3.3.2
2025-06-26 23:23:04,016:INFO:             IPython: 9.3.0
2025-06-26 23:23:04,016:INFO:          ipywidgets: 8.1.7
2025-06-26 23:23:04,016:INFO:                tqdm: 4.67.1
2025-06-26 23:23:04,016:INFO:               numpy: 1.26.4
2025-06-26 23:23:04,016:INFO:              pandas: 2.1.4
2025-06-26 23:23:04,016:INFO:              jinja2: 3.1.6
2025-06-26 23:23:04,016:INFO:               scipy: 1.11.4
2025-06-26 23:23:04,016:INFO:              joblib: 1.3.2
2025-06-26 23:23:04,016:INFO:             sklearn: 1.4.2
2025-06-26 23:23:04,016:INFO:                pyod: 2.0.5
2025-06-26 23:23:04,016:INFO:            imblearn: 0.13.0
2025-06-26 23:23:04,016:INFO:   category_encoders: 2.7.0
2025-06-26 23:23:04,016:INFO:            lightgbm: 4.6.0
2025-06-26 23:23:04,018:INFO:               numba: 0.61.2
2025-06-26 23:23:04,018:INFO:            requests: 2.32.4
2025-06-26 23:23:04,018:INFO:          matplotlib: 3.7.5
2025-06-26 23:23:04,018:INFO:          scikitplot: 0.3.7
2025-06-26 23:23:04,018:INFO:         yellowbrick: 1.5
2025-06-26 23:23:04,018:INFO:              plotly: 5.24.1
2025-06-26 23:23:04,018:INFO:    plotly-resampler: Not installed
2025-06-26 23:23:04,018:INFO:             kaleido: 1.0.0
2025-06-26 23:23:04,018:INFO:           schemdraw: 0.15
2025-06-26 23:23:04,018:INFO:         statsmodels: 0.14.4
2025-06-26 23:23:04,018:INFO:              sktime: 0.26.0
2025-06-26 23:23:04,018:INFO:               tbats: 1.1.3
2025-06-26 23:23:04,018:INFO:            pmdarima: 2.0.4
2025-06-26 23:23:04,018:INFO:              psutil: 7.0.0
2025-06-26 23:23:04,018:INFO:          markupsafe: 3.0.2
2025-06-26 23:23:04,018:INFO:             pickle5: Not installed
2025-06-26 23:23:04,018:INFO:         cloudpickle: 3.1.1
2025-06-26 23:23:04,018:INFO:         deprecation: 2.1.0
2025-06-26 23:23:04,018:INFO:              xxhash: 3.5.0
2025-06-26 23:23:04,018:INFO:           wurlitzer: Not installed
2025-06-26 23:23:04,018:INFO:PyCaret optional dependencies:
2025-06-26 23:23:04,018:INFO:                shap: Not installed
2025-06-26 23:23:04,018:INFO:           interpret: Not installed
2025-06-26 23:23:04,018:INFO:                umap: Not installed
2025-06-26 23:23:04,018:INFO:     ydata_profiling: Not installed
2025-06-26 23:23:04,018:INFO:  explainerdashboard: Not installed
2025-06-26 23:23:04,018:INFO:             autoviz: Not installed
2025-06-26 23:23:04,018:INFO:           fairlearn: Not installed
2025-06-26 23:23:04,018:INFO:          deepchecks: Not installed
2025-06-26 23:23:04,018:INFO:             xgboost: Not installed
2025-06-26 23:23:04,018:INFO:            catboost: Not installed
2025-06-26 23:23:04,018:INFO:              kmodes: Not installed
2025-06-26 23:23:04,018:INFO:             mlxtend: Not installed
2025-06-26 23:23:04,018:INFO:       statsforecast: Not installed
2025-06-26 23:23:04,018:INFO:        tune_sklearn: Not installed
2025-06-26 23:23:04,018:INFO:                 ray: Not installed
2025-06-26 23:23:04,018:INFO:            hyperopt: Not installed
2025-06-26 23:23:04,018:INFO:              optuna: Not installed
2025-06-26 23:23:04,018:INFO:               skopt: Not installed
2025-06-26 23:23:04,018:INFO:              mlflow: Not installed
2025-06-26 23:23:04,018:INFO:              gradio: Not installed
2025-06-26 23:23:04,018:INFO:             fastapi: Not installed
2025-06-26 23:23:04,018:INFO:             uvicorn: Not installed
2025-06-26 23:23:04,018:INFO:              m2cgen: Not installed
2025-06-26 23:23:04,018:INFO:           evidently: Not installed
2025-06-26 23:23:04,018:INFO:               fugue: Not installed
2025-06-26 23:23:04,018:INFO:           streamlit: Not installed
2025-06-26 23:23:04,018:INFO:             prophet: Not installed
2025-06-26 23:23:04,018:INFO:None
2025-06-26 23:23:04,018:INFO:Set up data.
2025-06-26 23:23:04,394:INFO:Set up folding strategy.
2025-06-26 23:23:04,394:INFO:Set up train/test split.
2025-06-26 23:23:05,046:INFO:Set up index.
2025-06-26 23:23:05,076:INFO:Assigning column types.
2025-06-26 23:23:05,525:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-26 23:23:05,525:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-26 23:23:05,529:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:23:05,531:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:06,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:06,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,030:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,034:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,499:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:06,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:06,525:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-26 23:23:06,528:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:23:06,531:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:07,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:07,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,041:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,504:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:07,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:07,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:07,530:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-26 23:23:07,535:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:08,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:08,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,555:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:08,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:08,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:08,555:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-26 23:23:09,023:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:09,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:09,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:09,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:09,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:09,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:23:09,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:09,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:09,533:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-26 23:23:10,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:10,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:10,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:10,518:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:23:10,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:10,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:10,543:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-26 23:23:11,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:11,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:11,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:11,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:11,543:INFO:Preparing preprocessing pipeline...
2025-06-26 23:23:11,543:INFO:Set up simple imputation.
2025-06-26 23:23:11,790:INFO:Set up encoding of categorical features.
2025-06-26 23:23:11,861:INFO:Set up column name cleaning.
2025-06-26 23:23:14,603:INFO:Finished creating preprocessing pipeline.
2025-06-26 23:23:14,607:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Admin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['median_sale_price',
                                             'median_list_price', 'median_ppsf',
                                             'median_list_ppsf', 'homes_sold',
                                             'pending_sales', 'new_listings',
                                             'inventory', 'median_dom',
                                             'avg_sale_to_list',
                                             'sold_above_list',
                                             'off_market_in_two_weeks',
                                             'zipcode', '...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=TargetEncoder(cols=['city',
                                                                    'city_full'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-26 23:23:14,607:INFO:Creating final display dataframe.
2025-06-26 23:23:18,399:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape      (884092, 38)
4        Transformed data shape      (884092, 38)
5   Transformed train set shape      (618864, 38)
6    Transformed test set shape      (265228, 38)
7              Numeric features                35
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              79e8
2025-06-26 23:23:18,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:18,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:19,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:19,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:23:19,375:INFO:setup() successfully completed in 15.36s...............
2025-06-26 23:23:23,070:INFO:Initializing compare_models()
2025-06-26 23:23:23,070:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025354F69A10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000025354F69A10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-26 23:23:23,070:INFO:Checking exceptions
2025-06-26 23:23:23,290:INFO:Preparing display monitor
2025-06-26 23:23:23,302:INFO:Initializing Linear Regression
2025-06-26 23:23:23,302:INFO:Total runtime is 0.0 minutes
2025-06-26 23:23:23,303:INFO:SubProcess create_model() called ==================================
2025-06-26 23:23:23,303:INFO:Initializing create_model()
2025-06-26 23:23:23,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025354F69A10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025344116310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:23:23,303:INFO:Checking exceptions
2025-06-26 23:23:23,303:INFO:Importing libraries
2025-06-26 23:23:23,305:INFO:Copying training dataset
2025-06-26 23:23:23,924:INFO:Defining folds
2025-06-26 23:23:23,924:INFO:Declaring metric variables
2025-06-26 23:23:23,926:INFO:Importing untrained model
2025-06-26 23:23:23,928:INFO:Linear Regression Imported successfully
2025-06-26 23:23:23,932:INFO:Starting cross validation
2025-06-26 23:23:23,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:23:33,688:INFO:Calculating mean and std
2025-06-26 23:23:33,690:INFO:Creating metrics dataframe
2025-06-26 23:23:33,692:INFO:Uploading results into container
2025-06-26 23:23:33,692:INFO:Uploading model into container now
2025-06-26 23:23:33,692:INFO:_master_model_container: 1
2025-06-26 23:23:33,692:INFO:_display_container: 2
2025-06-26 23:23:33,692:INFO:LinearRegression(n_jobs=-1)
2025-06-26 23:23:33,692:INFO:create_model() successfully completed......................................
2025-06-26 23:23:33,891:INFO:SubProcess create_model() end ==================================
2025-06-26 23:23:33,891:INFO:Creating metrics dataframe
2025-06-26 23:23:33,895:INFO:Initializing Lasso Regression
2025-06-26 23:23:33,895:INFO:Total runtime is 0.1765491525332133 minutes
2025-06-26 23:23:33,896:INFO:SubProcess create_model() called ==================================
2025-06-26 23:23:33,896:INFO:Initializing create_model()
2025-06-26 23:23:33,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025354F69A10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025344116310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:23:33,896:INFO:Checking exceptions
2025-06-26 23:23:33,896:INFO:Importing libraries
2025-06-26 23:23:33,896:INFO:Copying training dataset
2025-06-26 23:23:34,502:INFO:Defining folds
2025-06-26 23:23:34,502:INFO:Declaring metric variables
2025-06-26 23:23:34,504:INFO:Importing untrained model
2025-06-26 23:23:34,507:INFO:Lasso Regression Imported successfully
2025-06-26 23:23:34,511:INFO:Starting cross validation
2025-06-26 23:23:34,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:25:41,611:INFO:PyCaret RegressionExperiment
2025-06-26 23:25:41,612:INFO:Logging name: reg-default-name
2025-06-26 23:25:41,612:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-26 23:25:41,612:INFO:version 3.3.2
2025-06-26 23:25:41,612:INFO:Initializing setup()
2025-06-26 23:25:41,612:INFO:self.USI: 5d05
2025-06-26 23:25:41,612:INFO:self._variable_keys: {'fold_generator', 'y', 'fold_groups_param', 'log_plots_param', 'seed', '_available_plots', 'fold_shuffle_param', 'idx', 'memory', 'logging_param', 'y_train', 'y_test', 'X', 'exp_name_log', 'gpu_param', 'html_param', 'USI', '_ml_usecase', 'data', 'target_param', 'X_test', 'transform_target_param', 'pipeline', 'exp_id', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train'}
2025-06-26 23:25:41,612:INFO:Checking environment
2025-06-26 23:25:41,612:INFO:python_version: 3.11.9
2025-06-26 23:25:41,612:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-26 23:25:41,612:INFO:machine: AMD64
2025-06-26 23:25:41,612:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-26 23:25:41,619:INFO:Memory: svmem(total=66342375424, available=41382051840, percent=37.6, used=24960323584, free=41382051840)
2025-06-26 23:25:41,619:INFO:Physical Core: 8
2025-06-26 23:25:41,619:INFO:Logical Core: 16
2025-06-26 23:25:41,619:INFO:Checking libraries
2025-06-26 23:25:41,619:INFO:System:
2025-06-26 23:25:41,619:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-26 23:25:41,619:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-26 23:25:41,619:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-26 23:25:41,619:INFO:PyCaret required dependencies:
2025-06-26 23:25:41,620:INFO:                 pip: 25.1.1
2025-06-26 23:25:41,620:INFO:          setuptools: 65.5.0
2025-06-26 23:25:41,620:INFO:             pycaret: 3.3.2
2025-06-26 23:25:41,620:INFO:             IPython: 9.3.0
2025-06-26 23:25:41,620:INFO:          ipywidgets: 8.1.7
2025-06-26 23:25:41,620:INFO:                tqdm: 4.67.1
2025-06-26 23:25:41,620:INFO:               numpy: 1.26.4
2025-06-26 23:25:41,620:INFO:              pandas: 2.1.4
2025-06-26 23:25:41,620:INFO:              jinja2: 3.1.6
2025-06-26 23:25:41,620:INFO:               scipy: 1.11.4
2025-06-26 23:25:41,620:INFO:              joblib: 1.3.2
2025-06-26 23:25:41,620:INFO:             sklearn: 1.4.2
2025-06-26 23:25:41,620:INFO:                pyod: 2.0.5
2025-06-26 23:25:41,620:INFO:            imblearn: 0.13.0
2025-06-26 23:25:41,620:INFO:   category_encoders: 2.7.0
2025-06-26 23:25:41,620:INFO:            lightgbm: 4.6.0
2025-06-26 23:25:41,620:INFO:               numba: 0.61.2
2025-06-26 23:25:41,620:INFO:            requests: 2.32.4
2025-06-26 23:25:41,620:INFO:          matplotlib: 3.7.5
2025-06-26 23:25:41,620:INFO:          scikitplot: 0.3.7
2025-06-26 23:25:41,620:INFO:         yellowbrick: 1.5
2025-06-26 23:25:41,620:INFO:              plotly: 5.24.1
2025-06-26 23:25:41,620:INFO:    plotly-resampler: Not installed
2025-06-26 23:25:41,620:INFO:             kaleido: 1.0.0
2025-06-26 23:25:41,620:INFO:           schemdraw: 0.15
2025-06-26 23:25:41,620:INFO:         statsmodels: 0.14.4
2025-06-26 23:25:41,620:INFO:              sktime: 0.26.0
2025-06-26 23:25:41,620:INFO:               tbats: 1.1.3
2025-06-26 23:25:41,620:INFO:            pmdarima: 2.0.4
2025-06-26 23:25:41,620:INFO:              psutil: 7.0.0
2025-06-26 23:25:41,620:INFO:          markupsafe: 3.0.2
2025-06-26 23:25:41,620:INFO:             pickle5: Not installed
2025-06-26 23:25:41,620:INFO:         cloudpickle: 3.1.1
2025-06-26 23:25:41,620:INFO:         deprecation: 2.1.0
2025-06-26 23:25:41,620:INFO:              xxhash: 3.5.0
2025-06-26 23:25:41,620:INFO:           wurlitzer: Not installed
2025-06-26 23:25:41,620:INFO:PyCaret optional dependencies:
2025-06-26 23:25:41,620:INFO:                shap: Not installed
2025-06-26 23:25:41,620:INFO:           interpret: Not installed
2025-06-26 23:25:41,620:INFO:                umap: Not installed
2025-06-26 23:25:41,620:INFO:     ydata_profiling: Not installed
2025-06-26 23:25:41,620:INFO:  explainerdashboard: Not installed
2025-06-26 23:25:41,620:INFO:             autoviz: Not installed
2025-06-26 23:25:41,620:INFO:           fairlearn: Not installed
2025-06-26 23:25:41,620:INFO:          deepchecks: Not installed
2025-06-26 23:25:41,620:INFO:             xgboost: Not installed
2025-06-26 23:25:41,620:INFO:            catboost: Not installed
2025-06-26 23:25:41,620:INFO:              kmodes: Not installed
2025-06-26 23:25:41,620:INFO:             mlxtend: Not installed
2025-06-26 23:25:41,620:INFO:       statsforecast: Not installed
2025-06-26 23:25:41,620:INFO:        tune_sklearn: Not installed
2025-06-26 23:25:41,620:INFO:                 ray: Not installed
2025-06-26 23:25:41,620:INFO:            hyperopt: Not installed
2025-06-26 23:25:41,620:INFO:              optuna: Not installed
2025-06-26 23:25:41,620:INFO:               skopt: Not installed
2025-06-26 23:25:41,620:INFO:              mlflow: Not installed
2025-06-26 23:25:41,620:INFO:              gradio: Not installed
2025-06-26 23:25:41,621:INFO:             fastapi: Not installed
2025-06-26 23:25:41,621:INFO:             uvicorn: Not installed
2025-06-26 23:25:41,621:INFO:              m2cgen: Not installed
2025-06-26 23:25:41,621:INFO:           evidently: Not installed
2025-06-26 23:25:41,621:INFO:               fugue: Not installed
2025-06-26 23:25:41,621:INFO:           streamlit: Not installed
2025-06-26 23:25:41,621:INFO:             prophet: Not installed
2025-06-26 23:25:41,621:INFO:None
2025-06-26 23:25:41,621:INFO:Set up data.
2025-06-26 23:25:41,670:INFO:Set up folding strategy.
2025-06-26 23:25:41,670:INFO:Set up train/test split.
2025-06-26 23:25:41,737:INFO:Set up index.
2025-06-26 23:25:41,741:INFO:Assigning column types.
2025-06-26 23:25:41,811:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-26 23:25:41,812:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,815:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,817:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:41,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:41,935:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,937:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:25:41,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,056:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-26 23:25:42,058:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,061:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,175:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,178:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,294:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-26 23:25:42,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,408:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,413:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,527:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-26 23:25:42,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,768:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-26 23:25:42,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,970:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-26 23:25:42,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:42,996:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-26 23:25:43,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:43,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:43,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:43,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:43,220:INFO:Preparing preprocessing pipeline...
2025-06-26 23:25:43,220:INFO:Set up simple imputation.
2025-06-26 23:25:43,248:INFO:Set up encoding of categorical features.
2025-06-26 23:25:43,258:INFO:Set up column name cleaning.
2025-06-26 23:25:43,550:INFO:Finished creating preprocessing pipeline.
2025-06-26 23:25:43,553:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Admin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['median_sale_price',
                                             'median_list_price', 'median_ppsf',
                                             'median_list_ppsf', 'homes_sold',
                                             'pending_sales', 'new_listings',
                                             'inventory', 'median_dom',
                                             'avg_sale_to_list',
                                             'sold_above_list',
                                             'off_market_in_two_weeks',
                                             'zipcode', '...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=TargetEncoder(cols=['city',
                                                                    'city_full'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-26 23:25:43,553:INFO:Creating final display dataframe.
2025-06-26 23:25:44,186:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape      (100000, 38)
4        Transformed data shape      (100000, 38)
5   Transformed train set shape       (70000, 38)
6    Transformed test set shape       (30000, 38)
7              Numeric features                35
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              5d05
2025-06-26 23:25:44,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:44,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:44,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:44,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-26 23:25:44,416:INFO:setup() successfully completed in 2.81s...............
2025-06-26 23:25:46,115:INFO:Initializing compare_models()
2025-06-26 23:25:46,116:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-26 23:25:46,116:INFO:Checking exceptions
2025-06-26 23:25:46,142:INFO:Preparing display monitor
2025-06-26 23:25:46,156:INFO:Initializing Linear Regression
2025-06-26 23:25:46,157:INFO:Total runtime is 1.6792615254720053e-05 minutes
2025-06-26 23:25:46,160:INFO:SubProcess create_model() called ==================================
2025-06-26 23:25:46,160:INFO:Initializing create_model()
2025-06-26 23:25:46,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:25:46,160:INFO:Checking exceptions
2025-06-26 23:25:46,160:INFO:Importing libraries
2025-06-26 23:25:46,160:INFO:Copying training dataset
2025-06-26 23:25:46,239:INFO:Defining folds
2025-06-26 23:25:46,239:INFO:Declaring metric variables
2025-06-26 23:25:46,241:INFO:Importing untrained model
2025-06-26 23:25:46,244:INFO:Linear Regression Imported successfully
2025-06-26 23:25:46,248:INFO:Starting cross validation
2025-06-26 23:25:46,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:25:49,434:INFO:Calculating mean and std
2025-06-26 23:25:49,435:INFO:Creating metrics dataframe
2025-06-26 23:25:49,436:INFO:Uploading results into container
2025-06-26 23:25:49,436:INFO:Uploading model into container now
2025-06-26 23:25:49,437:INFO:_master_model_container: 1
2025-06-26 23:25:49,437:INFO:_display_container: 2
2025-06-26 23:25:49,437:INFO:LinearRegression(n_jobs=-1)
2025-06-26 23:25:49,437:INFO:create_model() successfully completed......................................
2025-06-26 23:25:49,608:INFO:SubProcess create_model() end ==================================
2025-06-26 23:25:49,609:INFO:Creating metrics dataframe
2025-06-26 23:25:49,614:INFO:Initializing Lasso Regression
2025-06-26 23:25:49,614:INFO:Total runtime is 0.05762737989425659 minutes
2025-06-26 23:25:49,616:INFO:SubProcess create_model() called ==================================
2025-06-26 23:25:49,616:INFO:Initializing create_model()
2025-06-26 23:25:49,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:25:49,616:INFO:Checking exceptions
2025-06-26 23:25:49,616:INFO:Importing libraries
2025-06-26 23:25:49,616:INFO:Copying training dataset
2025-06-26 23:25:49,715:INFO:Defining folds
2025-06-26 23:25:49,715:INFO:Declaring metric variables
2025-06-26 23:25:49,719:INFO:Importing untrained model
2025-06-26 23:25:49,722:INFO:Lasso Regression Imported successfully
2025-06-26 23:25:49,725:INFO:Starting cross validation
2025-06-26 23:25:49,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:25:53,581:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.030e+14, tolerance: 8.060e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:53,635:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e+14, tolerance: 7.893e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:53,657:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.257e+14, tolerance: 7.993e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:53,787:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e+14, tolerance: 7.962e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:57,948:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.319e+14, tolerance: 7.969e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:57,949:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+14, tolerance: 8.075e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:57,955:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.188e+14, tolerance: 8.024e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:58,143:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e+14, tolerance: 8.027e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:58,157:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e+14, tolerance: 8.059e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:58,171:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.259e+14, tolerance: 8.027e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:25:58,197:INFO:Calculating mean and std
2025-06-26 23:25:58,198:INFO:Creating metrics dataframe
2025-06-26 23:25:58,199:INFO:Uploading results into container
2025-06-26 23:25:58,199:INFO:Uploading model into container now
2025-06-26 23:25:58,200:INFO:_master_model_container: 2
2025-06-26 23:25:58,200:INFO:_display_container: 2
2025-06-26 23:25:58,200:INFO:Lasso(random_state=123)
2025-06-26 23:25:58,200:INFO:create_model() successfully completed......................................
2025-06-26 23:25:58,378:INFO:SubProcess create_model() end ==================================
2025-06-26 23:25:58,378:INFO:Creating metrics dataframe
2025-06-26 23:25:58,381:INFO:Initializing Ridge Regression
2025-06-26 23:25:58,382:INFO:Total runtime is 0.2037589987119039 minutes
2025-06-26 23:25:58,383:INFO:SubProcess create_model() called ==================================
2025-06-26 23:25:58,383:INFO:Initializing create_model()
2025-06-26 23:25:58,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:25:58,384:INFO:Checking exceptions
2025-06-26 23:25:58,384:INFO:Importing libraries
2025-06-26 23:25:58,384:INFO:Copying training dataset
2025-06-26 23:25:58,449:INFO:Defining folds
2025-06-26 23:25:58,450:INFO:Declaring metric variables
2025-06-26 23:25:58,452:INFO:Importing untrained model
2025-06-26 23:25:58,454:INFO:Ridge Regression Imported successfully
2025-06-26 23:25:58,457:INFO:Starting cross validation
2025-06-26 23:25:58,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:25:58,841:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.20466e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-26 23:25:58,981:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.35105e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-26 23:25:59,123:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=6.01933e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-26 23:25:59,168:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.49377e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-26 23:25:59,324:INFO:Calculating mean and std
2025-06-26 23:25:59,324:INFO:Creating metrics dataframe
2025-06-26 23:25:59,325:INFO:Uploading results into container
2025-06-26 23:25:59,327:INFO:Uploading model into container now
2025-06-26 23:25:59,327:INFO:_master_model_container: 3
2025-06-26 23:25:59,327:INFO:_display_container: 2
2025-06-26 23:25:59,327:INFO:Ridge(random_state=123)
2025-06-26 23:25:59,327:INFO:create_model() successfully completed......................................
2025-06-26 23:25:59,465:INFO:SubProcess create_model() end ==================================
2025-06-26 23:25:59,465:INFO:Creating metrics dataframe
2025-06-26 23:25:59,469:INFO:Initializing Elastic Net
2025-06-26 23:25:59,469:INFO:Total runtime is 0.2218766689300537 minutes
2025-06-26 23:25:59,471:INFO:SubProcess create_model() called ==================================
2025-06-26 23:25:59,471:INFO:Initializing create_model()
2025-06-26 23:25:59,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:25:59,472:INFO:Checking exceptions
2025-06-26 23:25:59,472:INFO:Importing libraries
2025-06-26 23:25:59,472:INFO:Copying training dataset
2025-06-26 23:25:59,546:INFO:Defining folds
2025-06-26 23:25:59,546:INFO:Declaring metric variables
2025-06-26 23:25:59,548:INFO:Importing untrained model
2025-06-26 23:25:59,552:INFO:Elastic Net Imported successfully
2025-06-26 23:25:59,555:INFO:Starting cross validation
2025-06-26 23:25:59,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:07,220:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.312e+14, tolerance: 8.027e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,236:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.995e+14, tolerance: 8.075e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.465e+14, tolerance: 8.059e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,272:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.233e+14, tolerance: 8.024e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,476:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+14, tolerance: 7.969e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,517:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e+14, tolerance: 8.027e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,541:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.075e+14, tolerance: 8.060e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,552:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.296e+14, tolerance: 7.993e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,615:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.275e+14, tolerance: 7.893e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,675:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e+14, tolerance: 7.962e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-26 23:26:07,702:INFO:Calculating mean and std
2025-06-26 23:26:07,703:INFO:Creating metrics dataframe
2025-06-26 23:26:07,704:INFO:Uploading results into container
2025-06-26 23:26:07,704:INFO:Uploading model into container now
2025-06-26 23:26:07,704:INFO:_master_model_container: 4
2025-06-26 23:26:07,704:INFO:_display_container: 2
2025-06-26 23:26:07,706:INFO:ElasticNet(random_state=123)
2025-06-26 23:26:07,706:INFO:create_model() successfully completed......................................
2025-06-26 23:26:07,841:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:07,841:INFO:Creating metrics dataframe
2025-06-26 23:26:07,845:INFO:Initializing Least Angle Regression
2025-06-26 23:26:07,845:INFO:Total runtime is 0.3614762941996257 minutes
2025-06-26 23:26:07,846:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:07,848:INFO:Initializing create_model()
2025-06-26 23:26:07,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:07,848:INFO:Checking exceptions
2025-06-26 23:26:07,848:INFO:Importing libraries
2025-06-26 23:26:07,848:INFO:Copying training dataset
2025-06-26 23:26:07,917:INFO:Defining folds
2025-06-26 23:26:07,918:INFO:Declaring metric variables
2025-06-26 23:26:07,920:INFO:Importing untrained model
2025-06-26 23:26:07,923:INFO:Least Angle Regression Imported successfully
2025-06-26 23:26:07,926:INFO:Starting cross validation
2025-06-26 23:26:07,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:08,311:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.499e+06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,313:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.158e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,313:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.015e+05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,314:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.331e+05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,314:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.311e+05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,314:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.644e+05, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,315:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.559e+05, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,315:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.495e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.306e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.980e+04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.027e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.731e+03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.918e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,316:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.181e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,318:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.395e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,319:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=7.139e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,319:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.245e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,319:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.173e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,340:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.530e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,340:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.172e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,358:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.214e+06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,420:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=9.979e+05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,421:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.334e+05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,421:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.744e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,422:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.047e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,423:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.959e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,423:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.440e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,423:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.978e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,425:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.303e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,425:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.901e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,425:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.764e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,425:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=6.360e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,462:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.278e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,462:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.247e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,462:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.345e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,463:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.484e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,463:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.619e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,463:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.792e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,521:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=9.255e+05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,521:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.067e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,522:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=7.164e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,522:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.256e+03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,522:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.257e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,522:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.712e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,561:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.568e+06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:08,590:INFO:Calculating mean and std
2025-06-26 23:26:08,592:INFO:Creating metrics dataframe
2025-06-26 23:26:08,593:INFO:Uploading results into container
2025-06-26 23:26:08,594:INFO:Uploading model into container now
2025-06-26 23:26:08,594:INFO:_master_model_container: 5
2025-06-26 23:26:08,594:INFO:_display_container: 2
2025-06-26 23:26:08,594:INFO:Lars(random_state=123)
2025-06-26 23:26:08,594:INFO:create_model() successfully completed......................................
2025-06-26 23:26:08,784:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:08,785:INFO:Creating metrics dataframe
2025-06-26 23:26:08,789:INFO:Initializing Lasso Least Angle Regression
2025-06-26 23:26:08,789:INFO:Total runtime is 0.3772069414456686 minutes
2025-06-26 23:26:08,791:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:08,791:INFO:Initializing create_model()
2025-06-26 23:26:08,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:08,791:INFO:Checking exceptions
2025-06-26 23:26:08,791:INFO:Importing libraries
2025-06-26 23:26:08,792:INFO:Copying training dataset
2025-06-26 23:26:08,860:INFO:Defining folds
2025-06-26 23:26:08,860:INFO:Declaring metric variables
2025-06-26 23:26:08,863:INFO:Importing untrained model
2025-06-26 23:26:08,865:INFO:Lasso Least Angle Regression Imported successfully
2025-06-26 23:26:08,868:INFO:Starting cross validation
2025-06-26 23:26:08,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:09,235:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=7.959e+04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,239:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 39 iterations, alpha=3.581e+04, previous alpha=3.098e+04, with an active set of 26 regressors.
  warnings.warn(

2025-06-26 23:26:09,251:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.237e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,252:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=5.693e+05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,253:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 29 iterations, alpha=3.499e+05, previous alpha=2.919e+05, with an active set of 22 regressors.
  warnings.warn(

2025-06-26 23:26:09,325:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.766e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,325:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.613e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,326:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.202e+06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,328:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=1.218e+06, previous alpha=1.102e+06, with an active set of 16 regressors.
  warnings.warn(

2025-06-26 23:26:09,360:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.527e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,361:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=2.374e+06, previous alpha=2.309e+06, with an active set of 13 regressors.
  warnings.warn(

2025-06-26 23:26:09,373:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.678e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,374:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 27 iterations, alpha=9.958e+05, previous alpha=2.395e+05, with an active set of 22 regressors.
  warnings.warn(

2025-06-26 23:26:09,425:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.001e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,427:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=1.527e+06, previous alpha=3.734e+05, with an active set of 19 regressors.
  warnings.warn(

2025-06-26 23:26:09,473:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.218e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,473:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.109e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,474:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.532e+05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,474:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.548e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-26 23:26:09,474:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=1.831e+05, previous alpha=1.819e+05, with an active set of 20 regressors.
  warnings.warn(

2025-06-26 23:26:09,510:INFO:Calculating mean and std
2025-06-26 23:26:09,511:INFO:Creating metrics dataframe
2025-06-26 23:26:09,512:INFO:Uploading results into container
2025-06-26 23:26:09,513:INFO:Uploading model into container now
2025-06-26 23:26:09,513:INFO:_master_model_container: 6
2025-06-26 23:26:09,513:INFO:_display_container: 2
2025-06-26 23:26:09,514:INFO:LassoLars(random_state=123)
2025-06-26 23:26:09,514:INFO:create_model() successfully completed......................................
2025-06-26 23:26:09,760:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:09,761:INFO:Creating metrics dataframe
2025-06-26 23:26:09,768:INFO:Initializing Orthogonal Matching Pursuit
2025-06-26 23:26:09,768:INFO:Total runtime is 0.3935237566630046 minutes
2025-06-26 23:26:09,770:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:09,771:INFO:Initializing create_model()
2025-06-26 23:26:09,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:09,771:INFO:Checking exceptions
2025-06-26 23:26:09,771:INFO:Importing libraries
2025-06-26 23:26:09,771:INFO:Copying training dataset
2025-06-26 23:26:09,854:INFO:Defining folds
2025-06-26 23:26:09,854:INFO:Declaring metric variables
2025-06-26 23:26:09,856:INFO:Importing untrained model
2025-06-26 23:26:09,859:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-26 23:26:09,862:INFO:Starting cross validation
2025-06-26 23:26:09,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:10,515:INFO:Calculating mean and std
2025-06-26 23:26:10,516:INFO:Creating metrics dataframe
2025-06-26 23:26:10,517:INFO:Uploading results into container
2025-06-26 23:26:10,518:INFO:Uploading model into container now
2025-06-26 23:26:10,518:INFO:_master_model_container: 7
2025-06-26 23:26:10,518:INFO:_display_container: 2
2025-06-26 23:26:10,518:INFO:OrthogonalMatchingPursuit()
2025-06-26 23:26:10,518:INFO:create_model() successfully completed......................................
2025-06-26 23:26:10,731:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:10,731:INFO:Creating metrics dataframe
2025-06-26 23:26:10,738:INFO:Initializing Bayesian Ridge
2025-06-26 23:26:10,739:INFO:Total runtime is 0.40970517794291184 minutes
2025-06-26 23:26:10,741:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:10,742:INFO:Initializing create_model()
2025-06-26 23:26:10,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:10,742:INFO:Checking exceptions
2025-06-26 23:26:10,742:INFO:Importing libraries
2025-06-26 23:26:10,742:INFO:Copying training dataset
2025-06-26 23:26:10,809:INFO:Defining folds
2025-06-26 23:26:10,810:INFO:Declaring metric variables
2025-06-26 23:26:10,812:INFO:Importing untrained model
2025-06-26 23:26:10,814:INFO:Bayesian Ridge Imported successfully
2025-06-26 23:26:10,818:INFO:Starting cross validation
2025-06-26 23:26:10,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:12,227:INFO:Calculating mean and std
2025-06-26 23:26:12,228:INFO:Creating metrics dataframe
2025-06-26 23:26:12,229:INFO:Uploading results into container
2025-06-26 23:26:12,229:INFO:Uploading model into container now
2025-06-26 23:26:12,229:INFO:_master_model_container: 8
2025-06-26 23:26:12,229:INFO:_display_container: 2
2025-06-26 23:26:12,230:INFO:BayesianRidge()
2025-06-26 23:26:12,230:INFO:create_model() successfully completed......................................
2025-06-26 23:26:12,457:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:12,457:INFO:Creating metrics dataframe
2025-06-26 23:26:12,462:INFO:Initializing Passive Aggressive Regressor
2025-06-26 23:26:12,462:INFO:Total runtime is 0.4384303331375123 minutes
2025-06-26 23:26:12,464:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:12,464:INFO:Initializing create_model()
2025-06-26 23:26:12,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:12,464:INFO:Checking exceptions
2025-06-26 23:26:12,464:INFO:Importing libraries
2025-06-26 23:26:12,464:INFO:Copying training dataset
2025-06-26 23:26:12,531:INFO:Defining folds
2025-06-26 23:26:12,531:INFO:Declaring metric variables
2025-06-26 23:26:12,534:INFO:Importing untrained model
2025-06-26 23:26:12,537:INFO:Passive Aggressive Regressor Imported successfully
2025-06-26 23:26:12,541:INFO:Starting cross validation
2025-06-26 23:26:12,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:13,393:INFO:Calculating mean and std
2025-06-26 23:26:13,394:INFO:Creating metrics dataframe
2025-06-26 23:26:13,394:INFO:Uploading results into container
2025-06-26 23:26:13,394:INFO:Uploading model into container now
2025-06-26 23:26:13,395:INFO:_master_model_container: 9
2025-06-26 23:26:13,395:INFO:_display_container: 2
2025-06-26 23:26:13,395:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-26 23:26:13,395:INFO:create_model() successfully completed......................................
2025-06-26 23:26:13,596:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:13,596:INFO:Creating metrics dataframe
2025-06-26 23:26:13,601:INFO:Initializing Huber Regressor
2025-06-26 23:26:13,602:INFO:Total runtime is 0.4574244618415833 minutes
2025-06-26 23:26:13,603:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:13,604:INFO:Initializing create_model()
2025-06-26 23:26:13,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:13,604:INFO:Checking exceptions
2025-06-26 23:26:13,604:INFO:Importing libraries
2025-06-26 23:26:13,604:INFO:Copying training dataset
2025-06-26 23:26:13,679:INFO:Defining folds
2025-06-26 23:26:13,680:INFO:Declaring metric variables
2025-06-26 23:26:13,684:INFO:Importing untrained model
2025-06-26 23:26:13,686:INFO:Huber Regressor Imported successfully
2025-06-26 23:26:13,689:INFO:Starting cross validation
2025-06-26 23:26:13,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:16,803:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:16,857:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:16,928:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:16,987:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:16,993:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,027:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,039:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,081:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,100:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,175:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-26 23:26:17,212:INFO:Calculating mean and std
2025-06-26 23:26:17,213:INFO:Creating metrics dataframe
2025-06-26 23:26:17,215:INFO:Uploading results into container
2025-06-26 23:26:17,215:INFO:Uploading model into container now
2025-06-26 23:26:17,215:INFO:_master_model_container: 10
2025-06-26 23:26:17,215:INFO:_display_container: 2
2025-06-26 23:26:17,216:INFO:HuberRegressor()
2025-06-26 23:26:17,216:INFO:create_model() successfully completed......................................
2025-06-26 23:26:17,405:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:17,405:INFO:Creating metrics dataframe
2025-06-26 23:26:17,410:INFO:Initializing K Neighbors Regressor
2025-06-26 23:26:17,410:INFO:Total runtime is 0.5209005077679952 minutes
2025-06-26 23:26:17,412:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:17,412:INFO:Initializing create_model()
2025-06-26 23:26:17,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:17,412:INFO:Checking exceptions
2025-06-26 23:26:17,412:INFO:Importing libraries
2025-06-26 23:26:17,412:INFO:Copying training dataset
2025-06-26 23:26:17,474:INFO:Defining folds
2025-06-26 23:26:17,474:INFO:Declaring metric variables
2025-06-26 23:26:17,477:INFO:Importing untrained model
2025-06-26 23:26:17,479:INFO:K Neighbors Regressor Imported successfully
2025-06-26 23:26:17,482:INFO:Starting cross validation
2025-06-26 23:26:17,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:20,371:INFO:Calculating mean and std
2025-06-26 23:26:20,372:INFO:Creating metrics dataframe
2025-06-26 23:26:20,374:INFO:Uploading results into container
2025-06-26 23:26:20,374:INFO:Uploading model into container now
2025-06-26 23:26:20,375:INFO:_master_model_container: 11
2025-06-26 23:26:20,375:INFO:_display_container: 2
2025-06-26 23:26:20,375:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-26 23:26:20,375:INFO:create_model() successfully completed......................................
2025-06-26 23:26:20,567:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:20,567:INFO:Creating metrics dataframe
2025-06-26 23:26:20,573:INFO:Initializing Decision Tree Regressor
2025-06-26 23:26:20,573:INFO:Total runtime is 0.573603892326355 minutes
2025-06-26 23:26:20,575:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:20,575:INFO:Initializing create_model()
2025-06-26 23:26:20,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:20,575:INFO:Checking exceptions
2025-06-26 23:26:20,575:INFO:Importing libraries
2025-06-26 23:26:20,575:INFO:Copying training dataset
2025-06-26 23:26:20,638:INFO:Defining folds
2025-06-26 23:26:20,639:INFO:Declaring metric variables
2025-06-26 23:26:20,641:INFO:Importing untrained model
2025-06-26 23:26:20,643:INFO:Decision Tree Regressor Imported successfully
2025-06-26 23:26:20,647:INFO:Starting cross validation
2025-06-26 23:26:20,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-26 23:26:25,059:INFO:Calculating mean and std
2025-06-26 23:26:25,060:INFO:Creating metrics dataframe
2025-06-26 23:26:25,062:INFO:Uploading results into container
2025-06-26 23:26:25,062:INFO:Uploading model into container now
2025-06-26 23:26:25,063:INFO:_master_model_container: 12
2025-06-26 23:26:25,063:INFO:_display_container: 2
2025-06-26 23:26:25,063:INFO:DecisionTreeRegressor(random_state=123)
2025-06-26 23:26:25,063:INFO:create_model() successfully completed......................................
2025-06-26 23:26:25,277:INFO:SubProcess create_model() end ==================================
2025-06-26 23:26:25,277:INFO:Creating metrics dataframe
2025-06-26 23:26:25,286:INFO:Initializing Random Forest Regressor
2025-06-26 23:26:25,286:INFO:Total runtime is 0.6521660248438518 minutes
2025-06-26 23:26:25,289:INFO:SubProcess create_model() called ==================================
2025-06-26 23:26:25,290:INFO:Initializing create_model()
2025-06-26 23:26:25,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000253549D3490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002534979F310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-26 23:26:25,290:INFO:Checking exceptions
2025-06-26 23:26:25,290:INFO:Importing libraries
2025-06-26 23:26:25,290:INFO:Copying training dataset
2025-06-26 23:26:25,376:INFO:Defining folds
2025-06-26 23:26:25,376:INFO:Declaring metric variables
2025-06-26 23:26:25,380:INFO:Importing untrained model
2025-06-26 23:26:25,382:INFO:Random Forest Regressor Imported successfully
2025-06-26 23:26:25,386:INFO:Starting cross validation
2025-06-26 23:26:25,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:11:48,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 00:11:48,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 00:11:48,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 00:11:48,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 00:11:55,898:INFO:PyCaret RegressionExperiment
2025-06-27 00:11:55,898:INFO:Logging name: reg-default-name
2025-06-27 00:11:55,898:INFO:ML Usecase: MLUsecase.REGRESSION
2025-06-27 00:11:55,898:INFO:version 3.3.2
2025-06-27 00:11:55,898:INFO:Initializing setup()
2025-06-27 00:11:55,898:INFO:self.USI: 9542
2025-06-27 00:11:55,899:INFO:self._variable_keys: {'html_param', '_available_plots', 'y_test', 'X', 'idx', 'gpu_param', 'fold_generator', 'y', 'seed', 'fold_shuffle_param', 'transform_target_param', 'fold_groups_param', 'X_test', 'gpu_n_jobs_param', 'USI', 'X_train', 'memory', 'target_param', 'y_train', 'logging_param', 'n_jobs_param', 'data', 'pipeline', 'exp_id', 'log_plots_param', '_ml_usecase', 'exp_name_log'}
2025-06-27 00:11:55,899:INFO:Checking environment
2025-06-27 00:11:55,899:INFO:python_version: 3.11.9
2025-06-27 00:11:55,899:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-27 00:11:55,899:INFO:machine: AMD64
2025-06-27 00:11:55,899:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-27 00:11:55,903:INFO:Memory: svmem(total=66342375424, available=42764505088, percent=35.5, used=23577870336, free=42764505088)
2025-06-27 00:11:55,903:INFO:Physical Core: 8
2025-06-27 00:11:55,903:INFO:Logical Core: 16
2025-06-27 00:11:55,903:INFO:Checking libraries
2025-06-27 00:11:55,903:INFO:System:
2025-06-27 00:11:55,903:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-27 00:11:55,903:INFO:executable: c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Scripts\python.exe
2025-06-27 00:11:55,903:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-27 00:11:55,903:INFO:PyCaret required dependencies:
2025-06-27 00:11:55,917:INFO:                 pip: 25.1.1
2025-06-27 00:11:55,917:INFO:          setuptools: 65.5.0
2025-06-27 00:11:55,918:INFO:             pycaret: 3.3.2
2025-06-27 00:11:55,918:INFO:             IPython: 9.3.0
2025-06-27 00:11:55,918:INFO:          ipywidgets: 8.1.7
2025-06-27 00:11:55,918:INFO:                tqdm: 4.67.1
2025-06-27 00:11:55,918:INFO:               numpy: 1.26.4
2025-06-27 00:11:55,918:INFO:              pandas: 2.1.4
2025-06-27 00:11:55,918:INFO:              jinja2: 3.1.6
2025-06-27 00:11:55,918:INFO:               scipy: 1.11.4
2025-06-27 00:11:55,918:INFO:              joblib: 1.3.2
2025-06-27 00:11:55,918:INFO:             sklearn: 1.4.2
2025-06-27 00:11:55,918:INFO:                pyod: 2.0.5
2025-06-27 00:11:55,918:INFO:            imblearn: 0.13.0
2025-06-27 00:11:55,918:INFO:   category_encoders: 2.7.0
2025-06-27 00:11:55,918:INFO:            lightgbm: 4.6.0
2025-06-27 00:11:55,918:INFO:               numba: 0.61.2
2025-06-27 00:11:55,918:INFO:            requests: 2.32.4
2025-06-27 00:11:55,918:INFO:          matplotlib: 3.7.5
2025-06-27 00:11:55,918:INFO:          scikitplot: 0.3.7
2025-06-27 00:11:55,918:INFO:         yellowbrick: 1.5
2025-06-27 00:11:55,918:INFO:              plotly: 5.24.1
2025-06-27 00:11:55,918:INFO:    plotly-resampler: Not installed
2025-06-27 00:11:55,918:INFO:             kaleido: 1.0.0
2025-06-27 00:11:55,918:INFO:           schemdraw: 0.15
2025-06-27 00:11:55,918:INFO:         statsmodels: 0.14.4
2025-06-27 00:11:55,918:INFO:              sktime: 0.26.0
2025-06-27 00:11:55,918:INFO:               tbats: 1.1.3
2025-06-27 00:11:55,918:INFO:            pmdarima: 2.0.4
2025-06-27 00:11:55,918:INFO:              psutil: 7.0.0
2025-06-27 00:11:55,918:INFO:          markupsafe: 3.0.2
2025-06-27 00:11:55,918:INFO:             pickle5: Not installed
2025-06-27 00:11:55,918:INFO:         cloudpickle: 3.1.1
2025-06-27 00:11:55,918:INFO:         deprecation: 2.1.0
2025-06-27 00:11:55,918:INFO:              xxhash: 3.5.0
2025-06-27 00:11:55,918:INFO:           wurlitzer: Not installed
2025-06-27 00:11:55,918:INFO:PyCaret optional dependencies:
2025-06-27 00:11:55,922:INFO:                shap: Not installed
2025-06-27 00:11:55,922:INFO:           interpret: Not installed
2025-06-27 00:11:55,922:INFO:                umap: Not installed
2025-06-27 00:11:55,922:INFO:     ydata_profiling: Not installed
2025-06-27 00:11:55,922:INFO:  explainerdashboard: Not installed
2025-06-27 00:11:55,922:INFO:             autoviz: Not installed
2025-06-27 00:11:55,922:INFO:           fairlearn: Not installed
2025-06-27 00:11:55,922:INFO:          deepchecks: Not installed
2025-06-27 00:11:55,922:INFO:             xgboost: Not installed
2025-06-27 00:11:55,922:INFO:            catboost: Not installed
2025-06-27 00:11:55,922:INFO:              kmodes: Not installed
2025-06-27 00:11:55,922:INFO:             mlxtend: Not installed
2025-06-27 00:11:55,922:INFO:       statsforecast: Not installed
2025-06-27 00:11:55,922:INFO:        tune_sklearn: Not installed
2025-06-27 00:11:55,922:INFO:                 ray: Not installed
2025-06-27 00:11:55,922:INFO:            hyperopt: Not installed
2025-06-27 00:11:55,922:INFO:              optuna: Not installed
2025-06-27 00:11:55,922:INFO:               skopt: Not installed
2025-06-27 00:11:55,922:INFO:              mlflow: Not installed
2025-06-27 00:11:55,922:INFO:              gradio: Not installed
2025-06-27 00:11:55,922:INFO:             fastapi: Not installed
2025-06-27 00:11:55,922:INFO:             uvicorn: Not installed
2025-06-27 00:11:55,922:INFO:              m2cgen: Not installed
2025-06-27 00:11:55,922:INFO:           evidently: Not installed
2025-06-27 00:11:55,922:INFO:               fugue: Not installed
2025-06-27 00:11:55,922:INFO:           streamlit: Not installed
2025-06-27 00:11:55,922:INFO:             prophet: Not installed
2025-06-27 00:11:55,922:INFO:None
2025-06-27 00:11:55,922:INFO:Set up data.
2025-06-27 00:11:55,952:INFO:Set up folding strategy.
2025-06-27 00:11:55,952:INFO:Set up train/test split.
2025-06-27 00:11:55,972:INFO:Set up index.
2025-06-27 00:11:55,972:INFO:Assigning column types.
2025-06-27 00:11:56,006:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-27 00:11:56,006:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,006:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,017:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,073:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,086:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,101:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,103:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,193:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,194:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-06-27 00:11:56,196:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,267:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,356:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-06-27 00:11:56,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,525:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-06-27 00:11:56,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,689:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,689:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-27 00:11:56,754:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-06-27 00:11:56,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,851:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-06-27 00:11:56,935:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:56,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,019:INFO:Preparing preprocessing pipeline...
2025-06-27 00:11:57,019:INFO:Set up simple imputation.
2025-06-27 00:11:57,037:INFO:Set up encoding of categorical features.
2025-06-27 00:11:57,037:INFO:Set up column name cleaning.
2025-06-27 00:11:57,170:INFO:Finished creating preprocessing pipeline.
2025-06-27 00:11:57,170:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Admin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['median_sale_price',
                                             'median_list_price', 'median_ppsf',
                                             'median_list_ppsf', 'homes_sold',
                                             'pending_sales', 'new_listings',
                                             'inventory', 'median_dom',
                                             'avg_sale_to_list',
                                             'sold_above_list',
                                             'off_market_in_two_weeks',
                                             'zipcode', '...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['city', 'city_full'],
                                    transformer=TargetEncoder(cols=['city',
                                                                    'city_full'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-06-27 00:11:57,170:INFO:Creating final display dataframe.
2025-06-27 00:11:57,524:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape       (50000, 38)
4        Transformed data shape       (50000, 38)
5   Transformed train set shape       (35000, 38)
6    Transformed test set shape       (15000, 38)
7              Numeric features                35
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              9542
2025-06-27 00:11:57,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 00:11:57,696:INFO:setup() successfully completed in 1.8s...............
2025-06-27 00:11:57,702:INFO:Initializing compare_models()
2025-06-27 00:11:57,702:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-27 00:11:57,702:INFO:Checking exceptions
2025-06-27 00:11:57,704:INFO:Preparing display monitor
2025-06-27 00:11:57,737:INFO:Initializing Linear Regression
2025-06-27 00:11:57,737:INFO:Total runtime is 0.0 minutes
2025-06-27 00:11:57,740:INFO:SubProcess create_model() called ==================================
2025-06-27 00:11:57,740:INFO:Initializing create_model()
2025-06-27 00:11:57,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:11:57,741:INFO:Checking exceptions
2025-06-27 00:11:57,741:INFO:Importing libraries
2025-06-27 00:11:57,741:INFO:Copying training dataset
2025-06-27 00:11:57,779:INFO:Defining folds
2025-06-27 00:11:57,779:INFO:Declaring metric variables
2025-06-27 00:11:57,781:INFO:Importing untrained model
2025-06-27 00:11:57,783:INFO:Linear Regression Imported successfully
2025-06-27 00:11:57,787:INFO:Starting cross validation
2025-06-27 00:11:57,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:00,500:INFO:Calculating mean and std
2025-06-27 00:12:00,500:INFO:Creating metrics dataframe
2025-06-27 00:12:00,502:INFO:Uploading results into container
2025-06-27 00:12:00,502:INFO:Uploading model into container now
2025-06-27 00:12:00,502:INFO:_master_model_container: 1
2025-06-27 00:12:00,502:INFO:_display_container: 2
2025-06-27 00:12:00,502:INFO:LinearRegression(n_jobs=-1)
2025-06-27 00:12:00,502:INFO:create_model() successfully completed......................................
2025-06-27 00:12:00,578:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:00,578:INFO:Creating metrics dataframe
2025-06-27 00:12:00,594:INFO:Initializing Lasso Regression
2025-06-27 00:12:00,594:INFO:Total runtime is 0.04761351346969604 minutes
2025-06-27 00:12:00,594:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:00,594:INFO:Initializing create_model()
2025-06-27 00:12:00,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:00,594:INFO:Checking exceptions
2025-06-27 00:12:00,594:INFO:Importing libraries
2025-06-27 00:12:00,594:INFO:Copying training dataset
2025-06-27 00:12:00,638:INFO:Defining folds
2025-06-27 00:12:00,638:INFO:Declaring metric variables
2025-06-27 00:12:00,640:INFO:Importing untrained model
2025-06-27 00:12:00,642:INFO:Lasso Regression Imported successfully
2025-06-27 00:12:00,644:INFO:Starting cross validation
2025-06-27 00:12:00,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:02,431:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+14, tolerance: 3.859e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:02,436:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+14, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:02,457:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+14, tolerance: 3.910e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:02,491:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+14, tolerance: 3.931e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,848:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+14, tolerance: 3.849e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,881:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+14, tolerance: 3.802e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,890:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+14, tolerance: 3.822e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,900:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+14, tolerance: 3.811e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,914:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+14, tolerance: 3.845e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,967:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+14, tolerance: 3.880e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:04,993:INFO:Calculating mean and std
2025-06-27 00:12:04,994:INFO:Creating metrics dataframe
2025-06-27 00:12:04,994:INFO:Uploading results into container
2025-06-27 00:12:04,994:INFO:Uploading model into container now
2025-06-27 00:12:04,994:INFO:_master_model_container: 2
2025-06-27 00:12:04,994:INFO:_display_container: 2
2025-06-27 00:12:04,994:INFO:Lasso(random_state=123)
2025-06-27 00:12:04,994:INFO:create_model() successfully completed......................................
2025-06-27 00:12:05,077:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:05,077:INFO:Creating metrics dataframe
2025-06-27 00:12:05,077:INFO:Initializing Ridge Regression
2025-06-27 00:12:05,077:INFO:Total runtime is 0.12233118613560995 minutes
2025-06-27 00:12:05,086:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:05,086:INFO:Initializing create_model()
2025-06-27 00:12:05,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:05,086:INFO:Checking exceptions
2025-06-27 00:12:05,086:INFO:Importing libraries
2025-06-27 00:12:05,086:INFO:Copying training dataset
2025-06-27 00:12:05,127:INFO:Defining folds
2025-06-27 00:12:05,127:INFO:Declaring metric variables
2025-06-27 00:12:05,128:INFO:Importing untrained model
2025-06-27 00:12:05,128:INFO:Ridge Regression Imported successfully
2025-06-27 00:12:05,135:INFO:Starting cross validation
2025-06-27 00:12:05,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:05,377:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.30379e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:12:05,432:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=6.39358e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:12:05,478:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.38959e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:12:05,503:INFO:Calculating mean and std
2025-06-27 00:12:05,503:INFO:Creating metrics dataframe
2025-06-27 00:12:05,505:INFO:Uploading results into container
2025-06-27 00:12:05,505:INFO:Uploading model into container now
2025-06-27 00:12:05,505:INFO:_master_model_container: 3
2025-06-27 00:12:05,505:INFO:_display_container: 2
2025-06-27 00:12:05,505:INFO:Ridge(random_state=123)
2025-06-27 00:12:05,505:INFO:create_model() successfully completed......................................
2025-06-27 00:12:05,576:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:05,576:INFO:Creating metrics dataframe
2025-06-27 00:12:05,593:INFO:Initializing Elastic Net
2025-06-27 00:12:05,593:INFO:Total runtime is 0.13092431624730427 minutes
2025-06-27 00:12:05,596:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:05,596:INFO:Initializing create_model()
2025-06-27 00:12:05,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:05,596:INFO:Checking exceptions
2025-06-27 00:12:05,596:INFO:Importing libraries
2025-06-27 00:12:05,596:INFO:Copying training dataset
2025-06-27 00:12:05,631:INFO:Defining folds
2025-06-27 00:12:05,631:INFO:Declaring metric variables
2025-06-27 00:12:05,631:INFO:Importing untrained model
2025-06-27 00:12:05,631:INFO:Elastic Net Imported successfully
2025-06-27 00:12:05,640:INFO:Starting cross validation
2025-06-27 00:12:05,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:09,000:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+14, tolerance: 3.811e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,000:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+14, tolerance: 3.845e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,037:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+14, tolerance: 3.822e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,056:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+14, tolerance: 3.849e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,145:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+14, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,150:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+14, tolerance: 3.802e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,217:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+14, tolerance: 3.859e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,219:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+14, tolerance: 3.931e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,223:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+14, tolerance: 3.880e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+14, tolerance: 3.910e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:12:09,288:INFO:Calculating mean and std
2025-06-27 00:12:09,289:INFO:Creating metrics dataframe
2025-06-27 00:12:09,290:INFO:Uploading results into container
2025-06-27 00:12:09,290:INFO:Uploading model into container now
2025-06-27 00:12:09,290:INFO:_master_model_container: 4
2025-06-27 00:12:09,290:INFO:_display_container: 2
2025-06-27 00:12:09,290:INFO:ElasticNet(random_state=123)
2025-06-27 00:12:09,290:INFO:create_model() successfully completed......................................
2025-06-27 00:12:09,373:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:09,373:INFO:Creating metrics dataframe
2025-06-27 00:12:09,373:INFO:Initializing Least Angle Regression
2025-06-27 00:12:09,373:INFO:Total runtime is 0.19393020073572792 minutes
2025-06-27 00:12:09,383:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:09,383:INFO:Initializing create_model()
2025-06-27 00:12:09,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:09,383:INFO:Checking exceptions
2025-06-27 00:12:09,383:INFO:Importing libraries
2025-06-27 00:12:09,383:INFO:Copying training dataset
2025-06-27 00:12:09,422:INFO:Defining folds
2025-06-27 00:12:09,423:INFO:Declaring metric variables
2025-06-27 00:12:09,424:INFO:Importing untrained model
2025-06-27 00:12:09,426:INFO:Least Angle Regression Imported successfully
2025-06-27 00:12:09,429:INFO:Starting cross validation
2025-06-27 00:12:09,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:09,616:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.088e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,616:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.964e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,640:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.035e+06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,668:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.573e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.291e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.143e+06, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.515e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.263e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.729e+04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,689:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.360e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,691:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.358e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,691:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.863e+03, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,691:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.469e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,691:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.626e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,691:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.615e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,693:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.183e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,693:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.592e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,694:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.244e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,694:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.616e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,694:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.695e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,695:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.471e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,695:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.738e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,695:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.204e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,696:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.949e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,696:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=7.679e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,696:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.431e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,696:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.125e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,696:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.348e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,703:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.264e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,703:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.127e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,704:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.105e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,704:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.773e+05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,705:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.522e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,705:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.275e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,706:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.761e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,706:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.415e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,706:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.492e+03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,707:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.518e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,708:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.739e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,723:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.307e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,723:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.657e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,723:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.626e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.177e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.725e+04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.170e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.774e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.962e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.822e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.145e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.447e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.725e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,725:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=8.777e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,731:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.333e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,731:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.667e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,737:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.458e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,739:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.730e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.223e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.612e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.209e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.669e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.931e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.599e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.004e+03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.025e+03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.748e+03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.562e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.466e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.308e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,756:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.957e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:09,782:INFO:Calculating mean and std
2025-06-27 00:12:09,782:INFO:Creating metrics dataframe
2025-06-27 00:12:09,782:INFO:Uploading results into container
2025-06-27 00:12:09,785:INFO:Uploading model into container now
2025-06-27 00:12:09,785:INFO:_master_model_container: 5
2025-06-27 00:12:09,785:INFO:_display_container: 2
2025-06-27 00:12:09,785:INFO:Lars(random_state=123)
2025-06-27 00:12:09,785:INFO:create_model() successfully completed......................................
2025-06-27 00:12:09,873:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:09,873:INFO:Creating metrics dataframe
2025-06-27 00:12:09,873:INFO:Initializing Lasso Least Angle Regression
2025-06-27 00:12:09,873:INFO:Total runtime is 0.20226986805597938 minutes
2025-06-27 00:12:09,879:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:09,879:INFO:Initializing create_model()
2025-06-27 00:12:09,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:09,879:INFO:Checking exceptions
2025-06-27 00:12:09,879:INFO:Importing libraries
2025-06-27 00:12:09,879:INFO:Copying training dataset
2025-06-27 00:12:09,914:INFO:Defining folds
2025-06-27 00:12:09,914:INFO:Declaring metric variables
2025-06-27 00:12:09,917:INFO:Importing untrained model
2025-06-27 00:12:09,918:INFO:Lasso Least Angle Regression Imported successfully
2025-06-27 00:12:09,919:INFO:Starting cross validation
2025-06-27 00:12:09,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:10,151:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.320e+06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,153:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.324e+05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,155:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=7.418e+05, previous alpha=4.310e+05, with an active set of 19 regressors.
  warnings.warn(

2025-06-27 00:12:10,165:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.736e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,167:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.680e+03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,167:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.956e+03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,169:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.978e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,169:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.386e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,171:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.191e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,171:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.576e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,171:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=2.644e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,173:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.413e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,173:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.191e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,175:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.430e+06, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,181:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=2.135e+06, previous alpha=1.886e+05, with an active set of 23 regressors.
  warnings.warn(

2025-06-27 00:12:10,235:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.857e+04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,235:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.167e+04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,235:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.217e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,238:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=9.025e+03, previous alpha=1.930e+03, with an active set of 31 regressors.
  warnings.warn(

2025-06-27 00:12:10,246:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.265e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,248:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.737e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,248:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.627e+04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,248:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 42 iterations, alpha=2.815e+04, previous alpha=1.980e+04, with an active set of 27 regressors.
  warnings.warn(

2025-06-27 00:12:10,266:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.332e+03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=6.659e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=5.909e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.914e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.391e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.395e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,269:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.263e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,277:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.666e+06, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,277:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.332e+06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:12:10,286:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=1.965e+05, previous alpha=5.793e+04, with an active set of 25 regressors.
  warnings.warn(

2025-06-27 00:12:10,328:INFO:Calculating mean and std
2025-06-27 00:12:10,328:INFO:Creating metrics dataframe
2025-06-27 00:12:10,328:INFO:Uploading results into container
2025-06-27 00:12:10,328:INFO:Uploading model into container now
2025-06-27 00:12:10,328:INFO:_master_model_container: 6
2025-06-27 00:12:10,328:INFO:_display_container: 2
2025-06-27 00:12:10,328:INFO:LassoLars(random_state=123)
2025-06-27 00:12:10,328:INFO:create_model() successfully completed......................................
2025-06-27 00:12:10,408:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:10,408:INFO:Creating metrics dataframe
2025-06-27 00:12:10,420:INFO:Initializing Orthogonal Matching Pursuit
2025-06-27 00:12:10,420:INFO:Total runtime is 0.21137549479802448 minutes
2025-06-27 00:12:10,420:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:10,420:INFO:Initializing create_model()
2025-06-27 00:12:10,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:10,424:INFO:Checking exceptions
2025-06-27 00:12:10,424:INFO:Importing libraries
2025-06-27 00:12:10,424:INFO:Copying training dataset
2025-06-27 00:12:10,459:INFO:Defining folds
2025-06-27 00:12:10,459:INFO:Declaring metric variables
2025-06-27 00:12:10,461:INFO:Importing untrained model
2025-06-27 00:12:10,463:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-27 00:12:10,465:INFO:Starting cross validation
2025-06-27 00:12:10,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:10,804:INFO:Calculating mean and std
2025-06-27 00:12:10,804:INFO:Creating metrics dataframe
2025-06-27 00:12:10,806:INFO:Uploading results into container
2025-06-27 00:12:10,806:INFO:Uploading model into container now
2025-06-27 00:12:10,806:INFO:_master_model_container: 7
2025-06-27 00:12:10,806:INFO:_display_container: 2
2025-06-27 00:12:10,806:INFO:OrthogonalMatchingPursuit()
2025-06-27 00:12:10,806:INFO:create_model() successfully completed......................................
2025-06-27 00:12:10,878:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:10,878:INFO:Creating metrics dataframe
2025-06-27 00:12:10,894:INFO:Initializing Bayesian Ridge
2025-06-27 00:12:10,894:INFO:Total runtime is 0.21927724281946817 minutes
2025-06-27 00:12:10,894:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:10,894:INFO:Initializing create_model()
2025-06-27 00:12:10,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:10,894:INFO:Checking exceptions
2025-06-27 00:12:10,894:INFO:Importing libraries
2025-06-27 00:12:10,894:INFO:Copying training dataset
2025-06-27 00:12:10,934:INFO:Defining folds
2025-06-27 00:12:10,934:INFO:Declaring metric variables
2025-06-27 00:12:10,936:INFO:Importing untrained model
2025-06-27 00:12:10,937:INFO:Bayesian Ridge Imported successfully
2025-06-27 00:12:10,939:INFO:Starting cross validation
2025-06-27 00:12:10,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:11,495:INFO:Calculating mean and std
2025-06-27 00:12:11,495:INFO:Creating metrics dataframe
2025-06-27 00:12:11,497:INFO:Uploading results into container
2025-06-27 00:12:11,498:INFO:Uploading model into container now
2025-06-27 00:12:11,498:INFO:_master_model_container: 8
2025-06-27 00:12:11,498:INFO:_display_container: 2
2025-06-27 00:12:11,498:INFO:BayesianRidge()
2025-06-27 00:12:11,498:INFO:create_model() successfully completed......................................
2025-06-27 00:12:11,579:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:11,579:INFO:Creating metrics dataframe
2025-06-27 00:12:11,579:INFO:Initializing Passive Aggressive Regressor
2025-06-27 00:12:11,579:INFO:Total runtime is 0.23068941831588743 minutes
2025-06-27 00:12:11,588:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:11,588:INFO:Initializing create_model()
2025-06-27 00:12:11,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:11,588:INFO:Checking exceptions
2025-06-27 00:12:11,588:INFO:Importing libraries
2025-06-27 00:12:11,588:INFO:Copying training dataset
2025-06-27 00:12:11,616:INFO:Defining folds
2025-06-27 00:12:11,616:INFO:Declaring metric variables
2025-06-27 00:12:11,616:INFO:Importing untrained model
2025-06-27 00:12:11,627:INFO:Passive Aggressive Regressor Imported successfully
2025-06-27 00:12:11,630:INFO:Starting cross validation
2025-06-27 00:12:11,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:12,108:INFO:Calculating mean and std
2025-06-27 00:12:12,108:INFO:Creating metrics dataframe
2025-06-27 00:12:12,110:INFO:Uploading results into container
2025-06-27 00:12:12,110:INFO:Uploading model into container now
2025-06-27 00:12:12,110:INFO:_master_model_container: 9
2025-06-27 00:12:12,110:INFO:_display_container: 2
2025-06-27 00:12:12,110:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-27 00:12:12,110:INFO:create_model() successfully completed......................................
2025-06-27 00:12:12,223:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:12,223:INFO:Creating metrics dataframe
2025-06-27 00:12:12,227:INFO:Initializing Huber Regressor
2025-06-27 00:12:12,227:INFO:Total runtime is 0.241495672861735 minutes
2025-06-27 00:12:12,229:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:12,229:INFO:Initializing create_model()
2025-06-27 00:12:12,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:12,229:INFO:Checking exceptions
2025-06-27 00:12:12,230:INFO:Importing libraries
2025-06-27 00:12:12,230:INFO:Copying training dataset
2025-06-27 00:12:12,263:INFO:Defining folds
2025-06-27 00:12:12,263:INFO:Declaring metric variables
2025-06-27 00:12:12,265:INFO:Importing untrained model
2025-06-27 00:12:12,268:INFO:Huber Regressor Imported successfully
2025-06-27 00:12:12,271:INFO:Starting cross validation
2025-06-27 00:12:12,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:13,775:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,791:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,854:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,856:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,864:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,884:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,895:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,895:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,937:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,957:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:12:13,988:INFO:Calculating mean and std
2025-06-27 00:12:13,988:INFO:Creating metrics dataframe
2025-06-27 00:12:13,989:INFO:Uploading results into container
2025-06-27 00:12:13,989:INFO:Uploading model into container now
2025-06-27 00:12:13,989:INFO:_master_model_container: 10
2025-06-27 00:12:13,989:INFO:_display_container: 2
2025-06-27 00:12:13,989:INFO:HuberRegressor()
2025-06-27 00:12:13,989:INFO:create_model() successfully completed......................................
2025-06-27 00:12:14,070:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:14,070:INFO:Creating metrics dataframe
2025-06-27 00:12:14,070:INFO:Initializing K Neighbors Regressor
2025-06-27 00:12:14,070:INFO:Total runtime is 0.2722147544225057 minutes
2025-06-27 00:12:14,083:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:14,083:INFO:Initializing create_model()
2025-06-27 00:12:14,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:14,083:INFO:Checking exceptions
2025-06-27 00:12:14,083:INFO:Importing libraries
2025-06-27 00:12:14,083:INFO:Copying training dataset
2025-06-27 00:12:14,119:INFO:Defining folds
2025-06-27 00:12:14,119:INFO:Declaring metric variables
2025-06-27 00:12:14,122:INFO:Importing untrained model
2025-06-27 00:12:14,124:INFO:K Neighbors Regressor Imported successfully
2025-06-27 00:12:14,130:INFO:Starting cross validation
2025-06-27 00:12:14,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:15,015:INFO:Calculating mean and std
2025-06-27 00:12:15,015:INFO:Creating metrics dataframe
2025-06-27 00:12:15,017:INFO:Uploading results into container
2025-06-27 00:12:15,017:INFO:Uploading model into container now
2025-06-27 00:12:15,017:INFO:_master_model_container: 11
2025-06-27 00:12:15,017:INFO:_display_container: 2
2025-06-27 00:12:15,017:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-27 00:12:15,017:INFO:create_model() successfully completed......................................
2025-06-27 00:12:15,113:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:15,114:INFO:Creating metrics dataframe
2025-06-27 00:12:15,117:INFO:Initializing Decision Tree Regressor
2025-06-27 00:12:15,117:INFO:Total runtime is 0.289662500222524 minutes
2025-06-27 00:12:15,122:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:15,122:INFO:Initializing create_model()
2025-06-27 00:12:15,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:15,122:INFO:Checking exceptions
2025-06-27 00:12:15,122:INFO:Importing libraries
2025-06-27 00:12:15,122:INFO:Copying training dataset
2025-06-27 00:12:15,167:INFO:Defining folds
2025-06-27 00:12:15,167:INFO:Declaring metric variables
2025-06-27 00:12:15,169:INFO:Importing untrained model
2025-06-27 00:12:15,172:INFO:Decision Tree Regressor Imported successfully
2025-06-27 00:12:15,176:INFO:Starting cross validation
2025-06-27 00:12:15,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:12:16,701:INFO:Calculating mean and std
2025-06-27 00:12:16,701:INFO:Creating metrics dataframe
2025-06-27 00:12:16,703:INFO:Uploading results into container
2025-06-27 00:12:16,703:INFO:Uploading model into container now
2025-06-27 00:12:16,703:INFO:_master_model_container: 12
2025-06-27 00:12:16,703:INFO:_display_container: 2
2025-06-27 00:12:16,703:INFO:DecisionTreeRegressor(random_state=123)
2025-06-27 00:12:16,703:INFO:create_model() successfully completed......................................
2025-06-27 00:12:16,792:INFO:SubProcess create_model() end ==================================
2025-06-27 00:12:16,793:INFO:Creating metrics dataframe
2025-06-27 00:12:16,796:INFO:Initializing Random Forest Regressor
2025-06-27 00:12:16,796:INFO:Total runtime is 0.31764060656229653 minutes
2025-06-27 00:12:16,799:INFO:SubProcess create_model() called ==================================
2025-06-27 00:12:16,799:INFO:Initializing create_model()
2025-06-27 00:12:16,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:12:16,799:INFO:Checking exceptions
2025-06-27 00:12:16,799:INFO:Importing libraries
2025-06-27 00:12:16,799:INFO:Copying training dataset
2025-06-27 00:12:16,837:INFO:Defining folds
2025-06-27 00:12:16,837:INFO:Declaring metric variables
2025-06-27 00:12:16,841:INFO:Importing untrained model
2025-06-27 00:12:16,843:INFO:Random Forest Regressor Imported successfully
2025-06-27 00:12:16,846:INFO:Starting cross validation
2025-06-27 00:12:16,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:13:16,793:INFO:Calculating mean and std
2025-06-27 00:13:16,793:INFO:Creating metrics dataframe
2025-06-27 00:13:16,795:INFO:Uploading results into container
2025-06-27 00:13:16,795:INFO:Uploading model into container now
2025-06-27 00:13:16,795:INFO:_master_model_container: 13
2025-06-27 00:13:16,795:INFO:_display_container: 2
2025-06-27 00:13:16,795:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:13:16,795:INFO:create_model() successfully completed......................................
2025-06-27 00:13:16,904:INFO:SubProcess create_model() end ==================================
2025-06-27 00:13:16,904:INFO:Creating metrics dataframe
2025-06-27 00:13:16,923:INFO:Initializing Extra Trees Regressor
2025-06-27 00:13:16,942:INFO:Total runtime is 1.3200829863548278 minutes
2025-06-27 00:13:16,942:INFO:SubProcess create_model() called ==================================
2025-06-27 00:13:16,942:INFO:Initializing create_model()
2025-06-27 00:13:16,942:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:13:16,942:INFO:Checking exceptions
2025-06-27 00:13:16,942:INFO:Importing libraries
2025-06-27 00:13:16,942:INFO:Copying training dataset
2025-06-27 00:13:16,988:INFO:Defining folds
2025-06-27 00:13:16,989:INFO:Declaring metric variables
2025-06-27 00:13:16,991:INFO:Importing untrained model
2025-06-27 00:13:16,993:INFO:Extra Trees Regressor Imported successfully
2025-06-27 00:13:16,997:INFO:Starting cross validation
2025-06-27 00:13:16,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:13:40,180:INFO:Calculating mean and std
2025-06-27 00:13:40,181:INFO:Creating metrics dataframe
2025-06-27 00:13:40,183:INFO:Uploading results into container
2025-06-27 00:13:40,183:INFO:Uploading model into container now
2025-06-27 00:13:40,184:INFO:_master_model_container: 14
2025-06-27 00:13:40,184:INFO:_display_container: 2
2025-06-27 00:13:40,184:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:13:40,184:INFO:create_model() successfully completed......................................
2025-06-27 00:13:40,359:INFO:SubProcess create_model() end ==================================
2025-06-27 00:13:40,360:INFO:Creating metrics dataframe
2025-06-27 00:13:40,367:INFO:Initializing AdaBoost Regressor
2025-06-27 00:13:40,367:INFO:Total runtime is 1.710500892003377 minutes
2025-06-27 00:13:40,370:INFO:SubProcess create_model() called ==================================
2025-06-27 00:13:40,371:INFO:Initializing create_model()
2025-06-27 00:13:40,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:13:40,372:INFO:Checking exceptions
2025-06-27 00:13:40,372:INFO:Importing libraries
2025-06-27 00:13:40,372:INFO:Copying training dataset
2025-06-27 00:13:40,431:INFO:Defining folds
2025-06-27 00:13:40,431:INFO:Declaring metric variables
2025-06-27 00:13:40,434:INFO:Importing untrained model
2025-06-27 00:13:40,437:INFO:AdaBoost Regressor Imported successfully
2025-06-27 00:13:40,444:INFO:Starting cross validation
2025-06-27 00:13:40,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:13:48,416:INFO:Calculating mean and std
2025-06-27 00:13:48,416:INFO:Creating metrics dataframe
2025-06-27 00:13:48,416:INFO:Uploading results into container
2025-06-27 00:13:48,416:INFO:Uploading model into container now
2025-06-27 00:13:48,416:INFO:_master_model_container: 15
2025-06-27 00:13:48,416:INFO:_display_container: 2
2025-06-27 00:13:48,416:INFO:AdaBoostRegressor(random_state=123)
2025-06-27 00:13:48,416:INFO:create_model() successfully completed......................................
2025-06-27 00:13:48,523:INFO:SubProcess create_model() end ==================================
2025-06-27 00:13:48,523:INFO:Creating metrics dataframe
2025-06-27 00:13:48,529:INFO:Initializing Gradient Boosting Regressor
2025-06-27 00:13:48,529:INFO:Total runtime is 1.8465305725733436 minutes
2025-06-27 00:13:48,532:INFO:SubProcess create_model() called ==================================
2025-06-27 00:13:48,533:INFO:Initializing create_model()
2025-06-27 00:13:48,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:13:48,533:INFO:Checking exceptions
2025-06-27 00:13:48,533:INFO:Importing libraries
2025-06-27 00:13:48,533:INFO:Copying training dataset
2025-06-27 00:13:48,581:INFO:Defining folds
2025-06-27 00:13:48,581:INFO:Declaring metric variables
2025-06-27 00:13:48,581:INFO:Importing untrained model
2025-06-27 00:13:48,581:INFO:Gradient Boosting Regressor Imported successfully
2025-06-27 00:13:48,581:INFO:Starting cross validation
2025-06-27 00:13:48,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:14:15,418:INFO:Calculating mean and std
2025-06-27 00:14:15,419:INFO:Creating metrics dataframe
2025-06-27 00:14:15,420:INFO:Uploading results into container
2025-06-27 00:14:15,421:INFO:Uploading model into container now
2025-06-27 00:14:15,421:INFO:_master_model_container: 16
2025-06-27 00:14:15,421:INFO:_display_container: 2
2025-06-27 00:14:15,421:INFO:GradientBoostingRegressor(random_state=123)
2025-06-27 00:14:15,421:INFO:create_model() successfully completed......................................
2025-06-27 00:14:15,509:INFO:SubProcess create_model() end ==================================
2025-06-27 00:14:15,509:INFO:Creating metrics dataframe
2025-06-27 00:14:15,509:INFO:Initializing Light Gradient Boosting Machine
2025-06-27 00:14:15,509:INFO:Total runtime is 2.2961890975634254 minutes
2025-06-27 00:14:15,524:INFO:SubProcess create_model() called ==================================
2025-06-27 00:14:15,524:INFO:Initializing create_model()
2025-06-27 00:14:15,524:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:14:15,524:INFO:Checking exceptions
2025-06-27 00:14:15,524:INFO:Importing libraries
2025-06-27 00:14:15,525:INFO:Copying training dataset
2025-06-27 00:14:15,577:INFO:Defining folds
2025-06-27 00:14:15,577:INFO:Declaring metric variables
2025-06-27 00:14:15,581:INFO:Importing untrained model
2025-06-27 00:14:15,584:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-27 00:14:15,588:INFO:Starting cross validation
2025-06-27 00:14:15,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:14:17,362:INFO:Calculating mean and std
2025-06-27 00:14:17,362:INFO:Creating metrics dataframe
2025-06-27 00:14:17,365:INFO:Uploading results into container
2025-06-27 00:14:17,367:INFO:Uploading model into container now
2025-06-27 00:14:17,367:INFO:_master_model_container: 17
2025-06-27 00:14:17,367:INFO:_display_container: 2
2025-06-27 00:14:17,367:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:14:17,367:INFO:create_model() successfully completed......................................
2025-06-27 00:14:17,482:INFO:SubProcess create_model() end ==================================
2025-06-27 00:14:17,482:INFO:Creating metrics dataframe
2025-06-27 00:14:17,499:INFO:Initializing Dummy Regressor
2025-06-27 00:14:17,499:INFO:Total runtime is 2.3293544848759966 minutes
2025-06-27 00:14:17,504:INFO:SubProcess create_model() called ==================================
2025-06-27 00:14:17,504:INFO:Initializing create_model()
2025-06-27 00:14:17,504:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D377E1650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:14:17,504:INFO:Checking exceptions
2025-06-27 00:14:17,504:INFO:Importing libraries
2025-06-27 00:14:17,504:INFO:Copying training dataset
2025-06-27 00:14:17,548:INFO:Defining folds
2025-06-27 00:14:17,548:INFO:Declaring metric variables
2025-06-27 00:14:17,564:INFO:Importing untrained model
2025-06-27 00:14:17,565:INFO:Dummy Regressor Imported successfully
2025-06-27 00:14:17,565:INFO:Starting cross validation
2025-06-27 00:14:17,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:14:17,964:INFO:Calculating mean and std
2025-06-27 00:14:17,965:INFO:Creating metrics dataframe
2025-06-27 00:14:17,966:INFO:Uploading results into container
2025-06-27 00:14:17,966:INFO:Uploading model into container now
2025-06-27 00:14:17,966:INFO:_master_model_container: 18
2025-06-27 00:14:17,966:INFO:_display_container: 2
2025-06-27 00:14:17,966:INFO:DummyRegressor()
2025-06-27 00:14:17,966:INFO:create_model() successfully completed......................................
2025-06-27 00:14:18,061:INFO:SubProcess create_model() end ==================================
2025-06-27 00:14:18,061:INFO:Creating metrics dataframe
2025-06-27 00:14:18,066:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-27 00:14:18,071:INFO:Initializing create_model()
2025-06-27 00:14:18,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:14:18,071:INFO:Checking exceptions
2025-06-27 00:14:18,071:INFO:Importing libraries
2025-06-27 00:14:18,071:INFO:Copying training dataset
2025-06-27 00:14:18,134:INFO:Defining folds
2025-06-27 00:14:18,134:INFO:Declaring metric variables
2025-06-27 00:14:18,134:INFO:Importing untrained model
2025-06-27 00:14:18,134:INFO:Declaring custom model
2025-06-27 00:14:18,134:INFO:Extra Trees Regressor Imported successfully
2025-06-27 00:14:18,134:INFO:Cross validation set to False
2025-06-27 00:14:18,134:INFO:Fitting Model
2025-06-27 00:14:21,270:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:14:21,270:INFO:create_model() successfully completed......................................
2025-06-27 00:14:21,393:INFO:_master_model_container: 18
2025-06-27 00:14:21,393:INFO:_display_container: 2
2025-06-27 00:14:21,394:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:14:21,394:INFO:compare_models() successfully completed......................................
2025-06-27 00:16:24,569:INFO:Initializing compare_models()
2025-06-27 00:16:24,569:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-06-27 00:16:24,569:INFO:Checking exceptions
2025-06-27 00:16:24,583:INFO:Preparing display monitor
2025-06-27 00:16:24,599:INFO:Initializing Linear Regression
2025-06-27 00:16:24,599:INFO:Total runtime is 0.0 minutes
2025-06-27 00:16:24,602:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:24,602:INFO:Initializing create_model()
2025-06-27 00:16:24,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:24,602:INFO:Checking exceptions
2025-06-27 00:16:24,602:INFO:Importing libraries
2025-06-27 00:16:24,603:INFO:Copying training dataset
2025-06-27 00:16:24,639:INFO:Defining folds
2025-06-27 00:16:24,639:INFO:Declaring metric variables
2025-06-27 00:16:24,641:INFO:Importing untrained model
2025-06-27 00:16:24,643:INFO:Linear Regression Imported successfully
2025-06-27 00:16:24,648:INFO:Starting cross validation
2025-06-27 00:16:24,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:25,030:INFO:Calculating mean and std
2025-06-27 00:16:25,030:INFO:Creating metrics dataframe
2025-06-27 00:16:25,030:INFO:Uploading results into container
2025-06-27 00:16:25,030:INFO:Uploading model into container now
2025-06-27 00:16:25,030:INFO:_master_model_container: 19
2025-06-27 00:16:25,030:INFO:_display_container: 3
2025-06-27 00:16:25,030:INFO:LinearRegression(n_jobs=-1)
2025-06-27 00:16:25,030:INFO:create_model() successfully completed......................................
2025-06-27 00:16:25,105:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:25,105:INFO:Creating metrics dataframe
2025-06-27 00:16:25,122:INFO:Initializing Lasso Regression
2025-06-27 00:16:25,123:INFO:Total runtime is 0.008704928557078044 minutes
2025-06-27 00:16:25,124:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:25,124:INFO:Initializing create_model()
2025-06-27 00:16:25,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:25,124:INFO:Checking exceptions
2025-06-27 00:16:25,124:INFO:Importing libraries
2025-06-27 00:16:25,125:INFO:Copying training dataset
2025-06-27 00:16:25,157:INFO:Defining folds
2025-06-27 00:16:25,158:INFO:Declaring metric variables
2025-06-27 00:16:25,159:INFO:Importing untrained model
2025-06-27 00:16:25,161:INFO:Lasso Regression Imported successfully
2025-06-27 00:16:25,165:INFO:Starting cross validation
2025-06-27 00:16:25,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:28,533:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e+14, tolerance: 3.802e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,722:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e+14, tolerance: 3.849e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,789:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+14, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,836:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+14, tolerance: 3.931e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,839:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+14, tolerance: 3.822e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,850:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+14, tolerance: 3.880e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,854:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+14, tolerance: 3.811e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,871:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+14, tolerance: 3.845e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,885:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+14, tolerance: 3.910e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,888:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+14, tolerance: 3.859e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:28,906:INFO:Calculating mean and std
2025-06-27 00:16:28,906:INFO:Creating metrics dataframe
2025-06-27 00:16:28,906:INFO:Uploading results into container
2025-06-27 00:16:28,906:INFO:Uploading model into container now
2025-06-27 00:16:28,906:INFO:_master_model_container: 20
2025-06-27 00:16:28,906:INFO:_display_container: 3
2025-06-27 00:16:28,906:INFO:Lasso(random_state=123)
2025-06-27 00:16:28,906:INFO:create_model() successfully completed......................................
2025-06-27 00:16:28,990:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:28,990:INFO:Creating metrics dataframe
2025-06-27 00:16:29,000:INFO:Initializing Ridge Regression
2025-06-27 00:16:29,000:INFO:Total runtime is 0.07333922386169434 minutes
2025-06-27 00:16:29,002:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:29,002:INFO:Initializing create_model()
2025-06-27 00:16:29,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:29,002:INFO:Checking exceptions
2025-06-27 00:16:29,002:INFO:Importing libraries
2025-06-27 00:16:29,002:INFO:Copying training dataset
2025-06-27 00:16:29,036:INFO:Defining folds
2025-06-27 00:16:29,036:INFO:Declaring metric variables
2025-06-27 00:16:29,038:INFO:Importing untrained model
2025-06-27 00:16:29,040:INFO:Ridge Regression Imported successfully
2025-06-27 00:16:29,040:INFO:Starting cross validation
2025-06-27 00:16:29,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:29,308:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.30379e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:16:29,371:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=6.39358e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:16:29,392:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.38959e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-06-27 00:16:29,412:INFO:Calculating mean and std
2025-06-27 00:16:29,412:INFO:Creating metrics dataframe
2025-06-27 00:16:29,412:INFO:Uploading results into container
2025-06-27 00:16:29,412:INFO:Uploading model into container now
2025-06-27 00:16:29,412:INFO:_master_model_container: 21
2025-06-27 00:16:29,412:INFO:_display_container: 3
2025-06-27 00:16:29,412:INFO:Ridge(random_state=123)
2025-06-27 00:16:29,412:INFO:create_model() successfully completed......................................
2025-06-27 00:16:29,504:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:29,504:INFO:Creating metrics dataframe
2025-06-27 00:16:29,508:INFO:Initializing Elastic Net
2025-06-27 00:16:29,508:INFO:Total runtime is 0.0818034847577413 minutes
2025-06-27 00:16:29,508:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:29,508:INFO:Initializing create_model()
2025-06-27 00:16:29,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:29,508:INFO:Checking exceptions
2025-06-27 00:16:29,508:INFO:Importing libraries
2025-06-27 00:16:29,508:INFO:Copying training dataset
2025-06-27 00:16:29,541:INFO:Defining folds
2025-06-27 00:16:29,541:INFO:Declaring metric variables
2025-06-27 00:16:29,541:INFO:Importing untrained model
2025-06-27 00:16:29,549:INFO:Elastic Net Imported successfully
2025-06-27 00:16:29,553:INFO:Starting cross validation
2025-06-27 00:16:29,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:32,810:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+14, tolerance: 3.802e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:32,913:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+14, tolerance: 3.849e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:32,970:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+14, tolerance: 3.845e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,002:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+14, tolerance: 3.811e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+14, tolerance: 3.822e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,084:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+14, tolerance: 3.910e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,084:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+14, tolerance: 3.902e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,104:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+14, tolerance: 3.880e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,114:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+14, tolerance: 3.931e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,114:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+14, tolerance: 3.859e+11
  model = cd_fast.enet_coordinate_descent(

2025-06-27 00:16:33,145:INFO:Calculating mean and std
2025-06-27 00:16:33,146:INFO:Creating metrics dataframe
2025-06-27 00:16:33,147:INFO:Uploading results into container
2025-06-27 00:16:33,147:INFO:Uploading model into container now
2025-06-27 00:16:33,148:INFO:_master_model_container: 22
2025-06-27 00:16:33,148:INFO:_display_container: 3
2025-06-27 00:16:33,148:INFO:ElasticNet(random_state=123)
2025-06-27 00:16:33,148:INFO:create_model() successfully completed......................................
2025-06-27 00:16:33,237:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:33,237:INFO:Creating metrics dataframe
2025-06-27 00:16:33,240:INFO:Initializing Least Angle Regression
2025-06-27 00:16:33,240:INFO:Total runtime is 0.14401289621988933 minutes
2025-06-27 00:16:33,243:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:33,243:INFO:Initializing create_model()
2025-06-27 00:16:33,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:33,243:INFO:Checking exceptions
2025-06-27 00:16:33,243:INFO:Importing libraries
2025-06-27 00:16:33,243:INFO:Copying training dataset
2025-06-27 00:16:33,279:INFO:Defining folds
2025-06-27 00:16:33,279:INFO:Declaring metric variables
2025-06-27 00:16:33,281:INFO:Importing untrained model
2025-06-27 00:16:33,282:INFO:Least Angle Regression Imported successfully
2025-06-27 00:16:33,286:INFO:Starting cross validation
2025-06-27 00:16:33,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:33,482:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.088e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,482:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.964e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,491:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.035e+06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,530:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.573e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,536:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.183e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,536:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.592e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.244e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.616e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.695e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.471e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.738e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.204e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.949e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,538:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=7.679e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,540:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.431e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,540:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.125e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,540:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.348e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,546:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.291e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,546:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.143e+06, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,546:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.515e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,548:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.263e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,548:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.729e+04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,548:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.360e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,548:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.358e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.863e+03, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.469e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.626e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.615e+02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.264e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.127e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,549:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.105e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.773e+05, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.522e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.275e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=5.761e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.415e+04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=8.492e+03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.518e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,551:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.739e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,577:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.307e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,577:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.657e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,577:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.626e+05, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,577:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.177e+05, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.725e+04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.170e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.774e+04, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.962e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.822e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.145e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.447e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.725e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,579:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=8.777e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,584:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.333e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,584:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.667e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,593:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.458e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,593:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.730e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.223e+06, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.612e+06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.209e+06, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.669e+05, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.931e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=4.599e+04, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=9.004e+03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.025e+03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.748e+03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.562e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.466e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.308e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,607:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.957e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,628:INFO:Calculating mean and std
2025-06-27 00:16:33,628:INFO:Creating metrics dataframe
2025-06-27 00:16:33,629:INFO:Uploading results into container
2025-06-27 00:16:33,629:INFO:Uploading model into container now
2025-06-27 00:16:33,629:INFO:_master_model_container: 23
2025-06-27 00:16:33,629:INFO:_display_container: 3
2025-06-27 00:16:33,629:INFO:Lars(random_state=123)
2025-06-27 00:16:33,629:INFO:create_model() successfully completed......................................
2025-06-27 00:16:33,732:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:33,732:INFO:Creating metrics dataframe
2025-06-27 00:16:33,745:INFO:Initializing Lasso Least Angle Regression
2025-06-27 00:16:33,745:INFO:Total runtime is 0.15242456992467246 minutes
2025-06-27 00:16:33,748:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:33,750:INFO:Initializing create_model()
2025-06-27 00:16:33,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:33,750:INFO:Checking exceptions
2025-06-27 00:16:33,750:INFO:Importing libraries
2025-06-27 00:16:33,750:INFO:Copying training dataset
2025-06-27 00:16:33,786:INFO:Defining folds
2025-06-27 00:16:33,786:INFO:Declaring metric variables
2025-06-27 00:16:33,788:INFO:Importing untrained model
2025-06-27 00:16:33,790:INFO:Lasso Least Angle Regression Imported successfully
2025-06-27 00:16:33,792:INFO:Starting cross validation
2025-06-27 00:16:33,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:33,977:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.320e+06, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,977:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=9.324e+05, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:33,979:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=7.418e+05, previous alpha=4.310e+05, with an active set of 19 regressors.
  warnings.warn(

2025-06-27 00:16:34,010:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.736e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,010:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.680e+03, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,010:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.956e+03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.978e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.386e+03, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.191e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.576e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=2.644e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.413e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,012:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.191e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,021:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.430e+06, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,021:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 30 iterations, alpha=2.135e+06, previous alpha=1.886e+05, with an active set of 23 regressors.
  warnings.warn(

2025-06-27 00:16:34,049:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=3.857e+04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,049:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.167e+04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,049:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.217e+03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,049:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=9.025e+03, previous alpha=1.930e+03, with an active set of 31 regressors.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.332e+03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=6.659e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=5.909e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.914e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.391e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.395e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,067:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.263e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,072:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.265e+06, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,074:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.737e+04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,074:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.627e+04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,074:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 42 iterations, alpha=2.815e+04, previous alpha=1.980e+04, with an active set of 27 regressors.
  warnings.warn(

2025-06-27 00:16:34,113:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.666e+06, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,113:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.332e+06, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-06-27 00:16:34,115:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=1.965e+05, previous alpha=5.793e+04, with an active set of 25 regressors.
  warnings.warn(

2025-06-27 00:16:34,133:INFO:Calculating mean and std
2025-06-27 00:16:34,133:INFO:Creating metrics dataframe
2025-06-27 00:16:34,133:INFO:Uploading results into container
2025-06-27 00:16:34,133:INFO:Uploading model into container now
2025-06-27 00:16:34,133:INFO:_master_model_container: 24
2025-06-27 00:16:34,133:INFO:_display_container: 3
2025-06-27 00:16:34,133:INFO:LassoLars(random_state=123)
2025-06-27 00:16:34,136:INFO:create_model() successfully completed......................................
2025-06-27 00:16:34,217:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:34,217:INFO:Creating metrics dataframe
2025-06-27 00:16:34,217:INFO:Initializing Orthogonal Matching Pursuit
2025-06-27 00:16:34,217:INFO:Total runtime is 0.16029342810312908 minutes
2025-06-27 00:16:34,217:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:34,217:INFO:Initializing create_model()
2025-06-27 00:16:34,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:34,217:INFO:Checking exceptions
2025-06-27 00:16:34,217:INFO:Importing libraries
2025-06-27 00:16:34,217:INFO:Copying training dataset
2025-06-27 00:16:34,265:INFO:Defining folds
2025-06-27 00:16:34,265:INFO:Declaring metric variables
2025-06-27 00:16:34,268:INFO:Importing untrained model
2025-06-27 00:16:34,270:INFO:Orthogonal Matching Pursuit Imported successfully
2025-06-27 00:16:34,270:INFO:Starting cross validation
2025-06-27 00:16:34,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:34,633:INFO:Calculating mean and std
2025-06-27 00:16:34,633:INFO:Creating metrics dataframe
2025-06-27 00:16:34,633:INFO:Uploading results into container
2025-06-27 00:16:34,636:INFO:Uploading model into container now
2025-06-27 00:16:34,637:INFO:_master_model_container: 25
2025-06-27 00:16:34,637:INFO:_display_container: 3
2025-06-27 00:16:34,637:INFO:OrthogonalMatchingPursuit()
2025-06-27 00:16:34,637:INFO:create_model() successfully completed......................................
2025-06-27 00:16:34,752:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:34,752:INFO:Creating metrics dataframe
2025-06-27 00:16:34,752:INFO:Initializing Bayesian Ridge
2025-06-27 00:16:34,752:INFO:Total runtime is 0.1692170739173889 minutes
2025-06-27 00:16:34,752:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:34,752:INFO:Initializing create_model()
2025-06-27 00:16:34,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:34,752:INFO:Checking exceptions
2025-06-27 00:16:34,752:INFO:Importing libraries
2025-06-27 00:16:34,752:INFO:Copying training dataset
2025-06-27 00:16:34,802:INFO:Defining folds
2025-06-27 00:16:34,802:INFO:Declaring metric variables
2025-06-27 00:16:34,802:INFO:Importing untrained model
2025-06-27 00:16:34,808:INFO:Bayesian Ridge Imported successfully
2025-06-27 00:16:34,810:INFO:Starting cross validation
2025-06-27 00:16:34,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:35,284:INFO:Calculating mean and std
2025-06-27 00:16:35,285:INFO:Creating metrics dataframe
2025-06-27 00:16:35,286:INFO:Uploading results into container
2025-06-27 00:16:35,286:INFO:Uploading model into container now
2025-06-27 00:16:35,287:INFO:_master_model_container: 26
2025-06-27 00:16:35,287:INFO:_display_container: 3
2025-06-27 00:16:35,287:INFO:BayesianRidge()
2025-06-27 00:16:35,287:INFO:create_model() successfully completed......................................
2025-06-27 00:16:35,371:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:35,371:INFO:Creating metrics dataframe
2025-06-27 00:16:35,371:INFO:Initializing Passive Aggressive Regressor
2025-06-27 00:16:35,371:INFO:Total runtime is 0.1795201579729716 minutes
2025-06-27 00:16:35,371:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:35,371:INFO:Initializing create_model()
2025-06-27 00:16:35,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:35,371:INFO:Checking exceptions
2025-06-27 00:16:35,371:INFO:Importing libraries
2025-06-27 00:16:35,371:INFO:Copying training dataset
2025-06-27 00:16:35,405:INFO:Defining folds
2025-06-27 00:16:35,405:INFO:Declaring metric variables
2025-06-27 00:16:35,405:INFO:Importing untrained model
2025-06-27 00:16:35,420:INFO:Passive Aggressive Regressor Imported successfully
2025-06-27 00:16:35,421:INFO:Starting cross validation
2025-06-27 00:16:35,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:35,950:INFO:Calculating mean and std
2025-06-27 00:16:35,950:INFO:Creating metrics dataframe
2025-06-27 00:16:35,952:INFO:Uploading results into container
2025-06-27 00:16:35,952:INFO:Uploading model into container now
2025-06-27 00:16:35,952:INFO:_master_model_container: 27
2025-06-27 00:16:35,952:INFO:_display_container: 3
2025-06-27 00:16:35,952:INFO:PassiveAggressiveRegressor(random_state=123)
2025-06-27 00:16:35,952:INFO:create_model() successfully completed......................................
2025-06-27 00:16:36,037:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:36,037:INFO:Creating metrics dataframe
2025-06-27 00:16:36,040:INFO:Initializing Huber Regressor
2025-06-27 00:16:36,040:INFO:Total runtime is 0.19067650636037192 minutes
2025-06-27 00:16:36,040:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:36,040:INFO:Initializing create_model()
2025-06-27 00:16:36,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:36,040:INFO:Checking exceptions
2025-06-27 00:16:36,040:INFO:Importing libraries
2025-06-27 00:16:36,040:INFO:Copying training dataset
2025-06-27 00:16:36,078:INFO:Defining folds
2025-06-27 00:16:36,078:INFO:Declaring metric variables
2025-06-27 00:16:36,078:INFO:Importing untrained model
2025-06-27 00:16:36,078:INFO:Huber Regressor Imported successfully
2025-06-27 00:16:36,090:INFO:Starting cross validation
2025-06-27 00:16:36,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:37,620:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,639:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,657:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,749:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,762:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,762:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,762:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,794:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,802:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,812:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-06-27 00:16:37,832:INFO:Calculating mean and std
2025-06-27 00:16:37,832:INFO:Creating metrics dataframe
2025-06-27 00:16:37,832:INFO:Uploading results into container
2025-06-27 00:16:37,832:INFO:Uploading model into container now
2025-06-27 00:16:37,832:INFO:_master_model_container: 28
2025-06-27 00:16:37,832:INFO:_display_container: 3
2025-06-27 00:16:37,832:INFO:HuberRegressor()
2025-06-27 00:16:37,832:INFO:create_model() successfully completed......................................
2025-06-27 00:16:37,931:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:37,931:INFO:Creating metrics dataframe
2025-06-27 00:16:37,931:INFO:Initializing K Neighbors Regressor
2025-06-27 00:16:37,931:INFO:Total runtime is 0.2222021222114563 minutes
2025-06-27 00:16:37,938:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:37,938:INFO:Initializing create_model()
2025-06-27 00:16:37,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:37,938:INFO:Checking exceptions
2025-06-27 00:16:37,938:INFO:Importing libraries
2025-06-27 00:16:37,938:INFO:Copying training dataset
2025-06-27 00:16:37,976:INFO:Defining folds
2025-06-27 00:16:37,976:INFO:Declaring metric variables
2025-06-27 00:16:37,979:INFO:Importing untrained model
2025-06-27 00:16:37,979:INFO:K Neighbors Regressor Imported successfully
2025-06-27 00:16:37,982:INFO:Starting cross validation
2025-06-27 00:16:37,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:38,859:INFO:Calculating mean and std
2025-06-27 00:16:38,859:INFO:Creating metrics dataframe
2025-06-27 00:16:38,861:INFO:Uploading results into container
2025-06-27 00:16:38,862:INFO:Uploading model into container now
2025-06-27 00:16:38,862:INFO:_master_model_container: 29
2025-06-27 00:16:38,862:INFO:_display_container: 3
2025-06-27 00:16:38,862:INFO:KNeighborsRegressor(n_jobs=-1)
2025-06-27 00:16:38,862:INFO:create_model() successfully completed......................................
2025-06-27 00:16:38,947:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:38,947:INFO:Creating metrics dataframe
2025-06-27 00:16:38,947:INFO:Initializing Decision Tree Regressor
2025-06-27 00:16:38,947:INFO:Total runtime is 0.23913498322168986 minutes
2025-06-27 00:16:38,947:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:38,947:INFO:Initializing create_model()
2025-06-27 00:16:38,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:38,947:INFO:Checking exceptions
2025-06-27 00:16:38,947:INFO:Importing libraries
2025-06-27 00:16:38,947:INFO:Copying training dataset
2025-06-27 00:16:38,981:INFO:Defining folds
2025-06-27 00:16:38,981:INFO:Declaring metric variables
2025-06-27 00:16:38,981:INFO:Importing untrained model
2025-06-27 00:16:38,981:INFO:Decision Tree Regressor Imported successfully
2025-06-27 00:16:38,992:INFO:Starting cross validation
2025-06-27 00:16:38,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:16:40,564:INFO:Calculating mean and std
2025-06-27 00:16:40,564:INFO:Creating metrics dataframe
2025-06-27 00:16:40,564:INFO:Uploading results into container
2025-06-27 00:16:40,567:INFO:Uploading model into container now
2025-06-27 00:16:40,567:INFO:_master_model_container: 30
2025-06-27 00:16:40,567:INFO:_display_container: 3
2025-06-27 00:16:40,567:INFO:DecisionTreeRegressor(random_state=123)
2025-06-27 00:16:40,567:INFO:create_model() successfully completed......................................
2025-06-27 00:16:40,652:INFO:SubProcess create_model() end ==================================
2025-06-27 00:16:40,652:INFO:Creating metrics dataframe
2025-06-27 00:16:40,654:INFO:Initializing Random Forest Regressor
2025-06-27 00:16:40,654:INFO:Total runtime is 0.2675799369812012 minutes
2025-06-27 00:16:40,654:INFO:SubProcess create_model() called ==================================
2025-06-27 00:16:40,654:INFO:Initializing create_model()
2025-06-27 00:16:40,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:16:40,654:INFO:Checking exceptions
2025-06-27 00:16:40,654:INFO:Importing libraries
2025-06-27 00:16:40,654:INFO:Copying training dataset
2025-06-27 00:16:40,693:INFO:Defining folds
2025-06-27 00:16:40,693:INFO:Declaring metric variables
2025-06-27 00:16:40,693:INFO:Importing untrained model
2025-06-27 00:16:40,703:INFO:Random Forest Regressor Imported successfully
2025-06-27 00:16:40,703:INFO:Starting cross validation
2025-06-27 00:16:40,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:17:41,507:INFO:Calculating mean and std
2025-06-27 00:17:41,507:INFO:Creating metrics dataframe
2025-06-27 00:17:41,509:INFO:Uploading results into container
2025-06-27 00:17:41,509:INFO:Uploading model into container now
2025-06-27 00:17:41,509:INFO:_master_model_container: 31
2025-06-27 00:17:41,511:INFO:_display_container: 3
2025-06-27 00:17:41,511:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:17:41,511:INFO:create_model() successfully completed......................................
2025-06-27 00:17:41,619:INFO:SubProcess create_model() end ==================================
2025-06-27 00:17:41,619:INFO:Creating metrics dataframe
2025-06-27 00:17:41,624:INFO:Initializing Extra Trees Regressor
2025-06-27 00:17:41,624:INFO:Total runtime is 1.2837464849154157 minutes
2025-06-27 00:17:41,624:INFO:SubProcess create_model() called ==================================
2025-06-27 00:17:41,624:INFO:Initializing create_model()
2025-06-27 00:17:41,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:17:41,624:INFO:Checking exceptions
2025-06-27 00:17:41,624:INFO:Importing libraries
2025-06-27 00:17:41,624:INFO:Copying training dataset
2025-06-27 00:17:41,664:INFO:Defining folds
2025-06-27 00:17:41,664:INFO:Declaring metric variables
2025-06-27 00:17:41,667:INFO:Importing untrained model
2025-06-27 00:17:41,669:INFO:Extra Trees Regressor Imported successfully
2025-06-27 00:17:41,669:INFO:Starting cross validation
2025-06-27 00:17:41,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:18:04,033:INFO:Calculating mean and std
2025-06-27 00:18:04,034:INFO:Creating metrics dataframe
2025-06-27 00:18:04,035:INFO:Uploading results into container
2025-06-27 00:18:04,036:INFO:Uploading model into container now
2025-06-27 00:18:04,036:INFO:_master_model_container: 32
2025-06-27 00:18:04,036:INFO:_display_container: 3
2025-06-27 00:18:04,037:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:18:04,037:INFO:create_model() successfully completed......................................
2025-06-27 00:18:04,147:INFO:SubProcess create_model() end ==================================
2025-06-27 00:18:04,147:INFO:Creating metrics dataframe
2025-06-27 00:18:04,153:INFO:Initializing AdaBoost Regressor
2025-06-27 00:18:04,153:INFO:Total runtime is 1.6592202901840212 minutes
2025-06-27 00:18:04,154:INFO:SubProcess create_model() called ==================================
2025-06-27 00:18:04,154:INFO:Initializing create_model()
2025-06-27 00:18:04,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:18:04,154:INFO:Checking exceptions
2025-06-27 00:18:04,154:INFO:Importing libraries
2025-06-27 00:18:04,154:INFO:Copying training dataset
2025-06-27 00:18:04,189:INFO:Defining folds
2025-06-27 00:18:04,189:INFO:Declaring metric variables
2025-06-27 00:18:04,190:INFO:Importing untrained model
2025-06-27 00:18:04,192:INFO:AdaBoost Regressor Imported successfully
2025-06-27 00:18:04,197:INFO:Starting cross validation
2025-06-27 00:18:04,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:18:10,193:INFO:Calculating mean and std
2025-06-27 00:18:10,193:INFO:Creating metrics dataframe
2025-06-27 00:18:10,195:INFO:Uploading results into container
2025-06-27 00:18:10,195:INFO:Uploading model into container now
2025-06-27 00:18:10,196:INFO:_master_model_container: 33
2025-06-27 00:18:10,196:INFO:_display_container: 3
2025-06-27 00:18:10,197:INFO:AdaBoostRegressor(random_state=123)
2025-06-27 00:18:10,197:INFO:create_model() successfully completed......................................
2025-06-27 00:18:10,281:INFO:SubProcess create_model() end ==================================
2025-06-27 00:18:10,282:INFO:Creating metrics dataframe
2025-06-27 00:18:10,283:INFO:Initializing Gradient Boosting Regressor
2025-06-27 00:18:10,283:INFO:Total runtime is 1.7613899191220603 minutes
2025-06-27 00:18:10,283:INFO:SubProcess create_model() called ==================================
2025-06-27 00:18:10,283:INFO:Initializing create_model()
2025-06-27 00:18:10,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:18:10,283:INFO:Checking exceptions
2025-06-27 00:18:10,283:INFO:Importing libraries
2025-06-27 00:18:10,283:INFO:Copying training dataset
2025-06-27 00:18:10,315:INFO:Defining folds
2025-06-27 00:18:10,315:INFO:Declaring metric variables
2025-06-27 00:18:10,315:INFO:Importing untrained model
2025-06-27 00:18:10,327:INFO:Gradient Boosting Regressor Imported successfully
2025-06-27 00:18:10,331:INFO:Starting cross validation
2025-06-27 00:18:10,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:18:30,639:INFO:Calculating mean and std
2025-06-27 00:18:30,641:INFO:Creating metrics dataframe
2025-06-27 00:18:30,641:INFO:Uploading results into container
2025-06-27 00:18:30,641:INFO:Uploading model into container now
2025-06-27 00:18:30,641:INFO:_master_model_container: 34
2025-06-27 00:18:30,641:INFO:_display_container: 3
2025-06-27 00:18:30,641:INFO:GradientBoostingRegressor(random_state=123)
2025-06-27 00:18:30,641:INFO:create_model() successfully completed......................................
2025-06-27 00:18:30,724:INFO:SubProcess create_model() end ==================================
2025-06-27 00:18:30,724:INFO:Creating metrics dataframe
2025-06-27 00:18:30,741:INFO:Initializing Light Gradient Boosting Machine
2025-06-27 00:18:30,741:INFO:Total runtime is 2.102354085445404 minutes
2025-06-27 00:18:30,741:INFO:SubProcess create_model() called ==================================
2025-06-27 00:18:30,741:INFO:Initializing create_model()
2025-06-27 00:18:30,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:18:30,741:INFO:Checking exceptions
2025-06-27 00:18:30,741:INFO:Importing libraries
2025-06-27 00:18:30,741:INFO:Copying training dataset
2025-06-27 00:18:30,775:INFO:Defining folds
2025-06-27 00:18:30,776:INFO:Declaring metric variables
2025-06-27 00:18:30,778:INFO:Importing untrained model
2025-06-27 00:18:30,779:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-27 00:18:30,779:INFO:Starting cross validation
2025-06-27 00:18:30,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:18:32,309:INFO:Calculating mean and std
2025-06-27 00:18:32,309:INFO:Creating metrics dataframe
2025-06-27 00:18:32,311:INFO:Uploading results into container
2025-06-27 00:18:32,312:INFO:Uploading model into container now
2025-06-27 00:18:32,312:INFO:_master_model_container: 35
2025-06-27 00:18:32,312:INFO:_display_container: 3
2025-06-27 00:18:32,312:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:18:32,312:INFO:create_model() successfully completed......................................
2025-06-27 00:18:32,412:INFO:SubProcess create_model() end ==================================
2025-06-27 00:18:32,412:INFO:Creating metrics dataframe
2025-06-27 00:18:32,412:INFO:Initializing Dummy Regressor
2025-06-27 00:18:32,412:INFO:Total runtime is 2.130213940143585 minutes
2025-06-27 00:18:32,412:INFO:SubProcess create_model() called ==================================
2025-06-27 00:18:32,412:INFO:Initializing create_model()
2025-06-27 00:18:32,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017D3BB2BA10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:18:32,412:INFO:Checking exceptions
2025-06-27 00:18:32,412:INFO:Importing libraries
2025-06-27 00:18:32,412:INFO:Copying training dataset
2025-06-27 00:18:32,464:INFO:Defining folds
2025-06-27 00:18:32,464:INFO:Declaring metric variables
2025-06-27 00:18:32,466:INFO:Importing untrained model
2025-06-27 00:18:32,466:INFO:Dummy Regressor Imported successfully
2025-06-27 00:18:32,466:INFO:Starting cross validation
2025-06-27 00:18:32,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 00:18:32,822:INFO:Calculating mean and std
2025-06-27 00:18:32,822:INFO:Creating metrics dataframe
2025-06-27 00:18:32,822:INFO:Uploading results into container
2025-06-27 00:18:32,822:INFO:Uploading model into container now
2025-06-27 00:18:32,822:INFO:_master_model_container: 36
2025-06-27 00:18:32,822:INFO:_display_container: 3
2025-06-27 00:18:32,822:INFO:DummyRegressor()
2025-06-27 00:18:32,822:INFO:create_model() successfully completed......................................
2025-06-27 00:18:32,897:INFO:SubProcess create_model() end ==================================
2025-06-27 00:18:32,897:INFO:Creating metrics dataframe
2025-06-27 00:18:32,914:WARNING:c:\Users\Admin\Documents\DataScience\DataOps\MLOps\mlops_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-27 00:18:32,921:INFO:Initializing create_model()
2025-06-27 00:18:32,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000017D7547E550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 00:18:32,921:INFO:Checking exceptions
2025-06-27 00:18:32,921:INFO:Importing libraries
2025-06-27 00:18:32,921:INFO:Copying training dataset
2025-06-27 00:18:32,955:INFO:Defining folds
2025-06-27 00:18:32,955:INFO:Declaring metric variables
2025-06-27 00:18:32,955:INFO:Importing untrained model
2025-06-27 00:18:32,955:INFO:Declaring custom model
2025-06-27 00:18:32,956:INFO:Extra Trees Regressor Imported successfully
2025-06-27 00:18:32,956:INFO:Cross validation set to False
2025-06-27 00:18:32,956:INFO:Fitting Model
2025-06-27 00:18:35,359:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:18:35,359:INFO:create_model() successfully completed......................................
2025-06-27 00:18:35,454:INFO:_master_model_container: 36
2025-06-27 00:18:35,454:INFO:_display_container: 3
2025-06-27 00:18:35,454:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-06-27 00:18:35,454:INFO:compare_models() successfully completed......................................
